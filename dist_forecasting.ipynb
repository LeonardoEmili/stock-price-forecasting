{"cells":[{"cell_type":"markdown","source":["## Import required packages"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e862fc71-84e1-4af7-badc-898efadd0bc5"}}},{"cell_type":"code","source":["# Download required packages\n!pip -q install gdown missingno torch petastorm wandb\n\nfrom petastorm.pytorch import DataLoader\n# Disable petastorm.DataLoader annoying logger (enable when debugging)\nimport logging.config\nlogging.config.dictConfig({'version': 1, 'disable_existing_loggers': True})\n\n%matplotlib inline\n\nimport pyspark\nfrom pyspark.sql import *\nfrom pyspark.sql.types import *\nimport pyspark.sql.functions as F\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql.window import Window\n\nfrom petastorm.spark import SparkDatasetConverter, make_spark_converter\nspark.conf.set(SparkDatasetConverter.PARENT_CACHE_DIR_URL_CONF, 'file:///dbfs/tmp/petastorm/cache')\n\nfrom pyspark.ml.regression import RandomForestRegressor, DecisionTreeRegressor\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.linalg import Vectors, VectorUDT\nfrom pyspark.sql.functions import udf\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport missingno as msno\nimport torch\nimport re\nimport torch.nn as nn\nfrom typing import *\nimport datetime\nimport gdown\nimport dataclasses\nfrom operator import itemgetter\nfrom functools import partial\n\nimport wandb\nwandb.login(key='147339090e59f6a02bed0fa3f938a2b1ecbc567c')\n\nimport tqdm as tq\ndef tqdm(*args, **kwargs):\n  ''' Small trick to prevent tqdm printing newlines at each step. '''\n  return tq.tqdm(*args, **kwargs, leave=True, position=0)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d89c4672-97c1-49d3-9350-6008885da2ab"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"><span class=\"ansi-yellow-fg\">WARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\nFailed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\nwandb: W&amp;B API key is configured (use `wandb login --relogin` to force relogin)\nwandb: WARNING If you&#39;re specifying your api key in code, ensure this code is not shared publically.\nwandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\nwandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-yellow-fg\">WARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\nFailed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\nwandb: W&amp;B API key is configured (use `wandb login --relogin` to force relogin)\nwandb: WARNING If you&#39;re specifying your api key in code, ensure this code is not shared publically.\nwandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\nwandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Data aquisition\nWe retrieve our datasets and download them to a temporary directory in the driver node."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f76226d3-37ac-40d6-a417-a05ca05a7000"}}},{"cell_type":"code","source":["!rm -rf /tmp/data /tmp/__MACOSX\ngdown.download('https://drive.google.com/uc?id=1ggmDp-AWFzbQReLG0pLpQE_3fO0C0RnM', '/tmp/data.zip', quiet=False)\n!unzip -q /tmp/data.zip -d /tmp/\n!rm /tmp/data.zip"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c1efdeb-4084-4115-9920-536feac86d20"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Downloading...\nFrom: https://drive.google.com/uc?id=1ggmDp-AWFzbQReLG0pLpQE_3fO0C0RnM\nTo: /tmp/data.zip\n\r0.00B [00:00, ?B/s]\r4.72MB [00:00, 27.3MB/s]\r8.91MB [00:00, 30.5MB/s]\r17.3MB [00:00, 23.5MB/s]\r30.9MB [00:00, 45.7MB/s]\r38.3MB [00:01, 41.4MB/s]\r44.0MB [00:01, 42.6MB/s]\r50.9MB [00:01, 34.4MB/s]\r59.8MB [00:01, 44.1MB/s]\r67.6MB [00:01, 31.8MB/s]\r71.9MB [00:01, 36.8MB/s]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Downloading...\nFrom: https://drive.google.com/uc?id=1ggmDp-AWFzbQReLG0pLpQE_3fO0C0RnM\nTo: /tmp/data.zip\n\r0.00B [00:00, ?B/s]\r4.72MB [00:00, 27.3MB/s]\r8.91MB [00:00, 30.5MB/s]\r17.3MB [00:00, 23.5MB/s]\r30.9MB [00:00, 45.7MB/s]\r38.3MB [00:01, 41.4MB/s]\r44.0MB [00:01, 42.6MB/s]\r50.9MB [00:01, 34.4MB/s]\r59.8MB [00:01, 44.1MB/s]\r67.6MB [00:01, 31.8MB/s]\r71.9MB [00:01, 36.8MB/s]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Then we load the datasets to the DBFS."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"941ae011-778f-4659-9774-ff7df196b5b1"}}},{"cell_type":"code","source":["dbutils.fs.mv(\"file:/tmp/data\", \"dbfs:/data\", recurse=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"791fea85-d7b5-4432-b530-ddae393cc5d6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[3]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[3]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%fs ls /data/"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c18efa6b-4546-4cab-9e4b-582119acee64"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/data/.DS_Store",".DS_Store",6148],["dbfs:/data/key_stats_yahoo.csv","key_stats_yahoo.csv",2047081],["dbfs:/data/prices/","prices/",0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":[],"pivotAggregation":null,"xColumns":[],"yColumns":[]},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/data/.DS_Store</td><td>.DS_Store</td><td>6148</td></tr><tr><td>dbfs:/data/key_stats_yahoo.csv</td><td>key_stats_yahoo.csv</td><td>2047081</td></tr><tr><td>dbfs:/data/prices/</td><td>prices/</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%fs ls /data/"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5e7b9cc-713e-4303-a194-15a532c0757b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/data/.DS_Store",".DS_Store",6148],["dbfs:/data/key_stats_yahoo.csv","key_stats_yahoo.csv",2047081],["dbfs:/data/prices/","prices/",0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":[],"pivotAggregation":null,"xColumns":[],"yColumns":[]},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/data/.DS_Store</td><td>.DS_Store</td><td>6148</td></tr><tr><td>dbfs:/data/key_stats_yahoo.csv</td><td>key_stats_yahoo.csv</td><td>2047081</td></tr><tr><td>dbfs:/data/prices/</td><td>prices/</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Dataset loading"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"898c47b5-01c8-4a5c-86c1-58bd6334f04a"}}},{"cell_type":"code","source":["key_stats_df = spark.read.load(\"dbfs:/data/key_stats_yahoo.csv\", \n                           format=\"csv\",\n                           sep=\",\",\n                           inferSchema=\"true\",\n                           header=\"true\"\n                          )\n\nchosen_stocks = [\"aapl\", \"msft\", \"ge\", \"pfe\", \"t\"]\nkey_stats_df = key_stats_df.drop(key_stats_df.columns[0])\n# Filtering chosen stocks\nstock_dfs = []\nfor stock in chosen_stocks:\n    stock_dfs.append(key_stats_df.filter(key_stats_df[\"Ticker\"] == stock))\n\nkey_stats_df = stock_dfs[0]\nfor i in range(1, len(stock_dfs)):\n    key_stats_df = key_stats_df.unionAll(stock_dfs[i])\n\nkey_stats_df.schema['Date'].nullable = False\n\n# Use legacy format to parse dates\nspark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\nkey_stats_df = key_stats_df.withColumn(\"Date\", F.to_date(key_stats_df[\"Date\"], 'MM/dd/yyyy HH:mm'))\n\n# Cast numerical columns to double\nfor column in key_stats_df.columns[2:]:\n  key_stats_df = key_stats_df.withColumn(column, key_stats_df[column].cast(\"double\"))\n\n# Prices dataframes for every stock\nstock_files =  list(map(lambda x: x + \".csv\", chosen_stocks))\nprices_files = [f.path for f in dbutils.fs.ls('/data/prices/') if f.path.lower().split(\"/\")[-1] in stock_files]\ndfs_names = [f.rsplit('/', 1)[1][:-len('.csv')] for f in prices_files]\nprices_dfs = []\nfor f in tqdm(prices_files, desc='Reading stock price data', total=len(prices_files)):\n  df = spark.read.load(\n    f,\n    format=\"csv\",\n    sep=\",\",\n    inferSchema=\"true\",\n    header=\"true\"\n  )\n  df = df.withColumn(\"Date\", F.to_date(df[\"Date\"], 'dd-MM-yyyy'))\n  df.schema['Date'].nullable = False\n  prices_dfs.append(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"832ad8e5-1aed-43f4-8748-ec7a4ced09bd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\rReading stock price data:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rReading stock price data:  20%|██        | 1/5 [00:01&lt;00:05,  1.46s/it]\rReading stock price data:  40%|████      | 2/5 [00:02&lt;00:04,  1.45s/it]\rReading stock price data:  60%|██████    | 3/5 [00:04&lt;00:02,  1.33s/it]\rReading stock price data:  80%|████████  | 4/5 [00:05&lt;00:01,  1.30s/it]\rReading stock price data: 100%|██████████| 5/5 [00:06&lt;00:00,  1.31s/it]\rReading stock price data: 100%|██████████| 5/5 [00:06&lt;00:00,  1.34s/it]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\rReading stock price data:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rReading stock price data:  20%|██        | 1/5 [00:01&lt;00:05,  1.46s/it]\rReading stock price data:  40%|████      | 2/5 [00:02&lt;00:04,  1.45s/it]\rReading stock price data:  60%|██████    | 3/5 [00:04&lt;00:02,  1.33s/it]\rReading stock price data:  80%|████████  | 4/5 [00:05&lt;00:01,  1.30s/it]\rReading stock price data: 100%|██████████| 5/5 [00:06&lt;00:00,  1.31s/it]\rReading stock price data: 100%|██████████| 5/5 [00:06&lt;00:00,  1.34s/it]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Dataset analysis"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"be1bb73d-1713-4401-9ca9-cef3f47a976f"}}},{"cell_type":"code","source":["print(\"Prices dataframe format:\")\nprices_dfs[0].printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bd6040d0-f97c-4ef4-bd0d-3a1a8d4214a5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Prices dataframe format:\nroot\n |-- Date: date (nullable = true)\n |-- Low: double (nullable = true)\n |-- Open: double (nullable = true)\n |-- Volume: double (nullable = true)\n |-- High: double (nullable = true)\n |-- Close: double (nullable = true)\n |-- Adjusted Close: double (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Prices dataframe format:\nroot\n-- Date: date (nullable = true)\n-- Low: double (nullable = true)\n-- Open: double (nullable = true)\n-- Volume: double (nullable = true)\n-- High: double (nullable = true)\n-- Close: double (nullable = true)\n-- Adjusted Close: double (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"Key stats dataframe format:\")\nkey_stats_df.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc56a262-df2a-4a39-ab77-76f55ee2948c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Key stats dataframe format:\nroot\n |-- Date: date (nullable = true)\n |-- Ticker: string (nullable = true)\n |-- Price: double (nullable = true)\n |-- DE Ratio: double (nullable = true)\n |-- Trailing P/E: double (nullable = true)\n |-- Price/Sales: double (nullable = true)\n |-- Price/Book: double (nullable = true)\n |-- Profit Margin: double (nullable = true)\n |-- Operating Margin: double (nullable = true)\n |-- Return on Assets: double (nullable = true)\n |-- Return on Equity: double (nullable = true)\n |-- Revenue Per Share: double (nullable = true)\n |-- Market Cap: double (nullable = true)\n |-- Enterprise Value: double (nullable = true)\n |-- Forward P/E: double (nullable = true)\n |-- PEG Ratio: double (nullable = true)\n |-- Enterprise Value/Revenue: double (nullable = true)\n |-- Enterprise Value/EBITDA: double (nullable = true)\n |-- Revenue: double (nullable = true)\n |-- Gross Profit: double (nullable = true)\n |-- EBITDA: double (nullable = true)\n |-- Net Income Avl to Common : double (nullable = true)\n |-- Diluted EPS: double (nullable = true)\n |-- Earnings Growth: double (nullable = true)\n |-- Revenue Growth: double (nullable = true)\n |-- Total Cash: double (nullable = true)\n |-- Total Cash Per Share: double (nullable = true)\n |-- Total Debt: double (nullable = true)\n |-- Current Ratio: double (nullable = true)\n |-- Book Value Per Share: double (nullable = true)\n |-- Cash Flow: double (nullable = true)\n |-- Beta: double (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Key stats dataframe format:\nroot\n-- Date: date (nullable = true)\n-- Ticker: string (nullable = true)\n-- Price: double (nullable = true)\n-- DE Ratio: double (nullable = true)\n-- Trailing P/E: double (nullable = true)\n-- Price/Sales: double (nullable = true)\n-- Price/Book: double (nullable = true)\n-- Profit Margin: double (nullable = true)\n-- Operating Margin: double (nullable = true)\n-- Return on Assets: double (nullable = true)\n-- Return on Equity: double (nullable = true)\n-- Revenue Per Share: double (nullable = true)\n-- Market Cap: double (nullable = true)\n-- Enterprise Value: double (nullable = true)\n-- Forward P/E: double (nullable = true)\n-- PEG Ratio: double (nullable = true)\n-- Enterprise Value/Revenue: double (nullable = true)\n-- Enterprise Value/EBITDA: double (nullable = true)\n-- Revenue: double (nullable = true)\n-- Gross Profit: double (nullable = true)\n-- EBITDA: double (nullable = true)\n-- Net Income Avl to Common : double (nullable = true)\n-- Diluted EPS: double (nullable = true)\n-- Earnings Growth: double (nullable = true)\n-- Revenue Growth: double (nullable = true)\n-- Total Cash: double (nullable = true)\n-- Total Cash Per Share: double (nullable = true)\n-- Total Debt: double (nullable = true)\n-- Current Ratio: double (nullable = true)\n-- Book Value Per Share: double (nullable = true)\n-- Cash Flow: double (nullable = true)\n-- Beta: double (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Utility functions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"578db780-5427-4c43-8252-682b1a10c6d0"}}},{"cell_type":"code","source":["def prices_df_nan_summary(prices_dfs: List[pyspark.sql.DataFrame], names: List[str]) -> pd.DataFrame:\n  ''' Utility function to summarize columns that have missing values. '''\n  nan_dfs = []\n  for prices_df, name in tqdm(zip(prices_dfs, names), total=len(prices_dfs), desc='Generating prices summary ...'):\n    nan_absolute = prices_df.agg(*[F.count(F.when(F.isnull(c), c)).alias(c) for c in prices_df.columns]).first()\n    if any(nan_absolute):\n      # Simple conversion from Pyspark row -> Python set of values\n      values = set(nan_absolute.asDict().values()).difference({0})\n      # Either we don't have values for that row, or we have all of them (but Date which is non-nullable)\n      # Values contains the no. of NaN values and 0 in correspondance of the Date column\n      assert len(values) == 1\n      nan_count = values.pop()\n      nan_dfs.append((name, round(100*nan_count/prices_df.count(), 3), nan_count))\n\n  return pd.DataFrame(nan_dfs, columns=['Stock name', 'Missing data (%)', 'Count'])\n\ndef remove_trailing_nan(df: pyspark.sql.DataFrame, ticker: str, col: str = 'Low') -> pyspark.sql.DataFrame:\n  '''\n    A trick to detect if the input DataFrame ends with a contiguous collection of NaN rows, returns the dataframe without them.\n  '''\n  # The total number of rows of the dataframe\n  df_length = df.count()\n  \n  # Sort the input dataframe and add a new column to keep track of the relative position of each row\n  df_sorted_id = df.sort('Date').withColumn('id', F.row_number().over(Window.orderBy('Date')))\n  \n  # Tricky part here: create a new column called 'cumsum' that will store the progressive number of consecutive NaN in our dataset.\n  # Let's break it into smaller parts:\n  # 1) create an index generator that will partition by 'Low' values [(...,Null...), (...,value1,...), (...,value2...), ... (...)] and within rows order by date\n  # Example:\n  ## |2019-06-05|null|null|  null|null| null|          null|624|        21|\n  ## |2019-06-06|null|null|  null|null| null|          null|625|        22|\n  ## |2019-06-07|null|null|  null|null| null|          null|626|        23| <- last column is the cumulative sum (i.e. the number of consecutive NaN)\n  ## ...\n  ## |2019-05-09|23.2|11.5|   7.3|4.2|  16.2|          29.1|1  |         0|\n  ## |2019-05-10|23.2|11.5|   7.3|4.2|  16.2|          29.1|2  |         0|\n  # 2) assign to each row a progressive index starting from 1 if it has null in correspondance of Low, zero otherwise\n  # 3) store these values into a new column called cumsum (i.e. it behaves like pandas cumsum)\n  # 4) at the end, the row whose ID corresponds to the length of the dataframe will contain at column 'cumsum' the no. of trailing NaN values.\n  cumsum_df = df_sorted_id.withColumn('cumsum', F.when(F.isnull(df_sorted_id.Low), F.row_number().over(Window.partitionBy('Low').orderBy('Date'))).otherwise(0))\n\n  # Retrieve the \"last\" row and read the value of cumsum\n  end_idx = cumsum_df.where(cumsum_df['id'] == df_length).first().cumsum\n  \n  # Retain rows whose index is lower len(df) - end_idx + 1 (i.e. cut trailing NaN values)\n  return df_sorted_id.where(df_sorted_id['id'] <= df_length-end_idx+1)\n\n\ndef merge_prices_fundamentals(\n    prices_dfs: List[pyspark.sql.DataFrame],\n    key_stats_df: pyspark.sql.DataFrame,\n    dfs_names: List[str],\n    drop_cols: List[str] = ['Date', 'Ticker', 'Price']\n    ) -> List[pyspark.sql.DataFrame]:\n  # Define the target list of dataframes\n  prices_dfs_new = []\n  for ticker in tqdm(key_stats_df.select('Ticker').distinct().collect(), desc='Merging the datasets ...'):\n    ticker = ticker[0]\n    # Consider only stocks for which we have fundamental data\n    if ticker.upper() not in dfs_names: continue\n      \n    # The prices dataframe associated to the current ticker\n    prices_df_idx = dfs_names.index(ticker.upper())\n    prices_df = prices_dfs[prices_df_idx]\n    \n    # Retrieve financial reports for the current ticker\n    ticker_df = key_stats_df.filter(F.col('Ticker') == ticker)\n    \n    # Perform an inner join between the two dataframes, we first take all reports\n    # whose date is at most the prices date (then we will take the latest available)\n    joined_df = ticker_df.join(prices_df, ticker_df.Date <= prices_df.Date, how='inner')\n    \n    # Let's break this into smaller parts:\n    # 1) Add a new column for the date latest available report for that stock. To do that\n    #    we partition over **prices** Date using the Window object, and the the max over\n    #    **ticker** Date.\n    # 2) Retain those columns whose financial report date is the same as in ticker_df_max_date\n    # 3) Finally drop the **ticker** Date and other unused columns\n    joined_df = joined_df.withColumn('ticker_df_max_date', F.max(ticker_df['Date'])\\\n                      .over(Window.partitionBy(prices_df['Date'])))\\\n                      .where(ticker_df['Date'] == F.col('ticker_df_max_date'))\\\n                      .drop('ticker_df_max_date', 'High', 'Low', 'Open', 'Close')\\\n                      .drop(ticker_df['Date'])\\\n                      \n    # Return the usual list of dataframes\n    prices_dfs_new.append(joined_df)\n    \n  return prices_dfs_new\n    \n                \ndef fill_missing_days(\n  aggregate_dfs: List[pyspark.sql.DataFrame],\n  remove_weekends: bool = True,\n  end_date: str = '2014-01-01'\n) -> List[pyspark.sql.DataFrame]:\n  result_dfs = []\n  \n  @udf(\"boolean\")\n  def is_weekday(date: datetime) -> bool:\n      ''' Returns true if the provided date corresponds to a weekday. '''\n      return date.weekday() < 5\n    \n  for df in tqdm(aggregate_dfs, desc='Filling missing days ...'):\n    # In this case we apply the following steps in order to apply fill-forward to our dataset:\n    # 1) define a Window object the will over the dataset sorted with decreasing dates\n    # 2) compute the difference in days between consecutive rows (11/05/2021 - 07/05/2021 ==> 4 days)\n    #    and store it in a column named diff\n    # 3) compute an increasing index in the column seq that is the days gap we need to fill\n    # Example:\n    # |Date      | Adjusted close   |diff|seq|new_date  |\n    # |2021-04-09|116.80999755859375|   3|  1|2021-04-11|\n    # |2021-04-09|116.80999755859375|   3|  2|2021-04-10|\n    # |2021-04-09|116.80999755859375|   3|  3|2021-04-09|\n    # 4) create a new column new_date as the result of the computation F.col('Date') + F.col('diff') - F.col('seq')\n    # 5) only retain rows whose date is before the provided end_date\n    #\n    # N.B. if we want to bfill the values we should instead consider the dataframes with dates in ascending order,\n    # and subtract the value of F.col('diff') instead of summing it. Other parts of the code stays the same.\n    df = df\\\n    .withColumn('diff', F.datediff(F.lag(F.col('Date'),1).over(Window.orderBy(F.desc('Date'))), F.col('Date')))\\\n    .withColumn('seq', F.explode(F.sequence(F.lit(1), F.col(\"diff\"))))\\\n    .withColumn('new_date', (F.col('Date') + F.col('diff') - F.col('seq')))\\\n    .where(F.col('new_date') < pd.Timestamp(end_date))\n    \n    # If specified, remove weekends that are most likely created by us as synthetic data with the ffill technique\n    if remove_weekends:\n      df = df.where(is_weekday(F.col('new_date')))\n      \n    # Drop unecessary columns\n    df = df.drop('Date', 'diff', 'seq').withColumnRenamed('new_date', 'Date')\n    \n    # If the dataframe is actually non-empty, add it to the list of resulting dataframes\n    if df.count() > 0:\n      result_dfs.append(df)\n  return result_dfs\n\ndef missing_values_summary(df):\n  ''' Returns a utility summary to view missing values in our dataframe. '''\n  n = df.count()\n  \n  def to_percentage(x: pyspark.sql.column.Column, n: int) -> int:\n    ''' Utility function to compute the amount of missing values as a percentage of the original dataframe. '''\n    return F.round(100 * x / n, 3)\n  \n  # Aggregate using the count function over null values, and return a view over the obtained (single row) dataframe\n  return df.agg(*[to_percentage(F.count(F.when(F.isnull(c), c)), n).alias(c) for c in df.columns]).first()\n\ndef scale_features(dfs: List[pyspark.sql.DataFrame]):\n    ''' Scales the numerical features to unit variance. '''\n    \n    scalable_features = ['DE Ratio', 'Trailing P/E', 'Price/Sales', 'Price/Book',\n       'Profit Margin', 'Operating Margin', 'Return on Assets',\n       'Return on Equity', 'Revenue Per Share', 'Market Cap',\n       'Enterprise Value', 'PEG Ratio', 'Enterprise Value/Revenue',\n       'Enterprise Value/EBITDA', 'Revenue', 'Gross Profit', 'EBITDA',\n       'Net Income Avl to Common ', 'Diluted EPS', 'Earnings Growth',\n       'Revenue Growth', 'Total Cash', 'Total Cash Per Share', 'Total Debt',\n       'Current Ratio', 'Book Value Per Share', 'Cash Flow', 'Beta', 'Volume',\n       'Adjusted Close', 'SMA', 'RSI']\n    \n\n    # Aggregating dfs in a single one\n    aggregate_df = dfs[0]\n    for df in tqdm(dfs[1:], desc='Performing dfs union ...'):\n      aggregate_df = aggregate_df.union(df)\n      \n    # Computing means and stds for every column of the aggregate df\n    mean = aggregate_df.select(\n      [F.mean(F.col(column)) for column in scalable_features]\n    ).collect()[0]\n    \n    std = aggregate_df.select(\n      [F.stddev(F.col(column)) for column in scalable_features]\n    ).collect()[0]\n    \n    #summary = aggregate_df.select(scalable_features).summary(\"mean\", \"stddev\")\n    #mean = summary.filter(summary[\"summary\"] == \"mean\")#.select(scalable_features)\n    #std = summary.filter(summary[\"summary\"] == \"std\")\n    #print(mean)\n\n    \n    for i in tqdm(range(len(dfs)), desc='Scaling numerical features ...'):\n      # Scaling scalable features\n      for j, feature in enumerate(scalable_features):\n        dfs[i] = dfs[i].withColumn(feature, (dfs[i][feature]-mean[j])/std[j])\n        #dfs[i] = dfs[i].withColumn(feature, (dfs[i][feature]-mean[feature])/std[feature])\n    return mean[-3], std[-3]\n        \ndef impute_missing_values(\n  prices_dfs_new: List[pyspark.sql.DataFrame],\n  key_stats_df: pyspark.sql.DataFrame\n) -> Tuple[List[pyspark.sql.DataFrame], pyspark.sql.DataFrame]:\n  # define the window\n  window = Window.orderBy('Date').rowsBetween(Window.unboundedPreceding, 0)\n\n  # Forward filling values \n  # (ref. https://stackoverflow.com/questions/38131982/forward-fill-missing-values-in-spark-python/50422240#50422240)\n  for i in range(len(prices_dfs_new)):\n    for col_name in prices_dfs_new[i].schema.names:\n      col = F.last(prices_dfs_new[i][col_name], ignorenulls=True).over(window)\n      prices_dfs_new[i] = prices_dfs_new[i].withColumn(col_name, col)\n\n  # In this case this dataframe contains financial reports that may contain NaN values either because that\n  # metric was not available at that time OR because it was monitoring an initial stage of a company growth.\n  # What we do is to apply the classic fast-forward, and fill initial missing values with zeroes.\n  # Please note: we also discard the 'Forward P/E' column since the imputation here would introduce too much noise.\n  key_stats_df_new = key_stats_df.drop('Forward P/E')\n  for col_name in key_stats_df_new.schema.names:\n      col = F.last(key_stats_df_new[col_name], ignorenulls=True).over(window)\n      key_stats_df_new = key_stats_df_new.withColumn(col_name, col)\n  key_stats_df_new = key_stats_df_new.fillna(0.)\n  \n  return prices_dfs_new, key_stats_df_new\n\ndef from_dfs(\n  dfs: List[pyspark.sql.DataFrame],\n  window_size: int = 3,\n  target_col: str = 'Adjusted Close',\n  val_date: str = '2012-01-01',\n  test_date: str = '2013-01-01'\n):\n  # Split the dataset into train/val/test using these dates as boundaries\n  val_begin = pd.Timestamp(val_date)\n  test_begin = pd.Timestamp(test_date)\n  \n  def should_drop(col: pyspark.sql.column, idx: int) -> bool:\n    ''' Returns whether the provided column should be dropped. '''\n    return (col.endswith(f'_{idx}') or 'Ticker' in col or 'Date' in col or 'id' in col)\\\n              and col != f'Adjusted Close_{idx}'\n\n  train_split, val_split, test_split = [], [], []\n  \n  for df in tqdm(dfs, desc='Loading dataset from dfs ...'):\n    # Create an ID for each row based on dates\n    df = df\\\n      .sort('Date')\\\n      .withColumn('id', F.row_number().over(Window.orderBy('Date')))\n    \n    # Split the stock dataset into train/dev/test splits\n    train_df = df.where(F.col('Date') < val_begin)\n    val_df = df.where(F.col('Date').between(val_begin, test_begin-pd.Timedelta(days=1)))\n    test_df = df.where(F.col('Date') >= test_begin)\n    \n    # Add a unique identifier for each column (e.g. Date -> Date_0, Date_1, etc ...)\n    train_df = prepend_columns_index(train_df)\n    val_df = prepend_columns_index(val_df)\n    test_df = prepend_columns_index(test_df)\n    \n    # Convert each split from nxm -> nxm*(w+1), where w is the size of the window\n    train_df = create_window_indexes(train_df, window_size)\n    val_df = create_window_indexes(val_df, window_size)\n    test_df = create_window_indexes(test_df, window_size)\n    \n    # Collect the processed datasets\n    train_split.append(train_df)\n    val_split.append(val_df)\n    test_split.append(test_df)\n  \n  # Initialize the final datasets using the obtained df schema\n  train_ds = spark.createDataFrame([], train_split[0].schema)\n  val_ds = spark.createDataFrame([], val_split[0].schema)\n  test_ds = spark.createDataFrame([], test_split[0].schema)\n  \n  # Collect all the dataframes into a single df for each data split\n  for df in train_split: train_ds = train_ds.union(df)\n  for df in val_split: val_ds = val_ds.union(df)\n  for df in test_split: test_ds = test_ds.union(df)\n  \n  # Drop unused columns for the target variable and rename the target column as 'y'\n  drop_cols = [col for col in test_ds.columns if should_drop(col, window_size)]\n  train_ds = train_ds.drop(*drop_cols).withColumnRenamed(f'Adjusted Close_{window_size}', 'y')\n  val_ds = val_ds.drop(*drop_cols).withColumnRenamed(f'Adjusted Close_{window_size}', 'y')\n  test_ds = test_ds.drop(*drop_cols).withColumnRenamed(f'Adjusted Close_{window_size}', 'y')\n  \n  # Rename columns to make them compatible with Apache Parquet format\n  target_cols = list(map(lambda x: '_'.join(re.split(' |/', x)), train_ds.columns))\n  for c, target in zip(train_ds.columns, target_cols): train_ds = train_ds.withColumnRenamed(c, target)\n  for c, target in zip(val_ds.columns, target_cols): val_ds = val_ds.withColumnRenamed(c, target)\n  for c, target in zip(test_ds.columns, target_cols): test_ds = test_ds.withColumnRenamed(c, target)\n    \n  # Compute the set of unique features in each split\n  features = list(set(c[:-2] for c in train_ds.columns if len(c) >= 2))\n\n  # Convert each split to have, at each timestep (column), the collection of features at that timestep\n  for timestep in tqdm(range(window_size), desc='Creating timesteps ...'):\n    # Consider all the features in this timestep\n    current_cols = list(map(lambda c: f'{c}_{timestep}', features))\n    # Convert (price_0, sma_0, market_cap_0) -> 0: (price|sma|market_cap) \n    train_ds = train_ds.withColumn(f'x_{timestep}', F.array(current_cols)).drop(*current_cols)\n    val_ds = val_ds.withColumn(f'x_{timestep}', F.array(current_cols)).drop(*current_cols)\n    test_ds = test_ds.withColumn(f'x_{timestep}', F.array(current_cols)).drop(*current_cols)\n  \n  return train_ds, val_ds, test_ds, features\n\ndef prepend_columns_index(\n  df: pyspark.sql.DataFrame,\n  idx: int = 0\n) -> pyspark.sql.DataFrame:\n  ''' Utility function that returns a new dataframe where columns are preceeded by [idx]. '''\n  for col in df.schema.names:\n    # If this is not the first time this function is applied, simply edit the previous identifier\n    new_col = f'{col}_{idx}' if idx == 0 else f'{col[:-2]}_{idx}'\n    df = df.withColumnRenamed(col, new_col)\n  return df\n\ndef create_window_indexes(df: pyspark.sql.DataFrame, window_size: int) -> pyspark.sql.DataFrame:\n  ''' Apply self join multiple times to the input dataframe, return a new one of size (df.count(), len(df.columns)*window_size) '''\n  joined_df = df\n  for win_idx in range(1, window_size+1):\n    joined_df = joined_df.join(\n      prepend_columns_index(df, win_idx),\n      F.col('id_0') == F.col(f'id_{win_idx}') - win_idx\n    )\n  return joined_df\n\ndef collate_fn(\n  time_steps: List[str],\n  batch: List[Dict[str, np.array]]\n) -> Tuple[torch.Tensor, torch.Tensor]:\n  ''' Returns (x, y) pairs where x is a vector of shape: (window_size, feature_size). '''\n  X = np.asarray([np.stack(itemgetter(*time_steps)(d)) for d in batch])\n  Y = np.asarray([d['y'] for d in batch])\n  return torch.from_numpy(X).double(), torch.from_numpy(Y).double()\n\ndef data_loader_fn(window_size: int, **kwargs) -> DataLoader:\n  ''' Override default behaviour and return a petastorm.Dataset with custom collate function. '''\n  time_steps = [f'x_{time_step}' for time_step in range(window_size)]\n  return DataLoader(**kwargs, collate_fn=partial(collate_fn, time_steps))\n\ndef r2_score(y_hat: np.ndarray, y: np.ndarray) -> float:\n  ''' Computes the R Squared coefficient between y_hat and y. '''\n  rss = torch.sum((y - y_hat) ** 2)\n  tss = torch.sum((y - y.mean()) ** 2)\n  return 1 - rss / tss\n\ndef adjusted_r2_score(y_hat: np.ndarray, y: np.ndarray, p: int) -> float:\n  ''' Computes the Adjusted R Squared coefficient between y_hat and y. '''\n  rss = torch.sum((y - y_hat) ** 2)\n  tss = torch.sum((y - y.mean()) ** 2)\n  df_e = y.shape[0] - p - 1\n  df_t = y.shape[0] - 1\n  adj_coef = df_t/df_e if df_t/df_e > 0 else 1  # sample size < features\n  return 1 - (rss / tss) * adj_coef\n  \n\ndef plot_loss_history(loss_history):\n  ''' Plots the loss history. '''\n  plt.plot(loss_history['train_history'], label='Train loss')\n  plt.plot(loss_history['valid_history'], label='Valid loss')\n  plt.xlabel('Epochs')\n  plt.ylabel('Loss')\n  plt.legend(loc=\"upper right\")\n  plt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ebf7570c-7796-4442-9a41-c7a8e9069d60"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Technical indicators"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"707b227e-4c9c-4943-b14a-db5253fec795"}}},{"cell_type":"code","source":["def add_sma(dfs: List[pyspark.sql.DataFrame], period: int = 10) -> None:\n    ''' Computes the Simple Moving Average from a given dataframe. '''\n    # Window of previous [period] days.\n    w = (Window().orderBy(F.col(\"timestamp\").cast('long')).rangeBetween(-period*86400, 0))\n    for i in tqdm(range(len(dfs)), desc='Adding SMA ...'):\n        # Adding temporary timestamp column\n        dfs[i] = dfs[i].withColumn('timestamp', dfs[i].Date.cast('timestamp'))\n        # Computing moving average over the window\n        dfs[i] = dfs[i].withColumn(\n          \"SMA\",\n          F.avg(\"Adjusted Close\").over(w)\n        )\n        # Dropping temporary columns\n        dfs[i] = dfs[i].drop(\"timestamp\")\n\n        \ndef add_rsi(dfs: List[pyspark.sql.DataFrame], period: int = 14) -> None:\n    ''' Computes the Relative Strength Index from a given dataframe. \n        Formula available at https://en.wikipedia.org/wiki/Relative_strength_index.\n        Also adds overbought and oversold when the RSI index hits 70 or 30.'''\n    for j in tqdm(range(len(dfs)), desc='Adding RSI ...'):\n        \n        #dateCol = dfs[j][\"Date\"]\n        w = Window.orderBy(\"Date\")\n\n        # Lagging the adjusted close of one row (to have the price of the previous day)\n        dfs[j] = dfs[j].withColumn(\"prev_adj_close\", F.lag(dfs[j][\"Adjusted Close\"]).over(w))\n        # Computing day gain and day loss\n        dfs[j] = dfs[j].withColumn(\"current_gain\", F.when(dfs[j][\"Adjusted Close\"] >= dfs[j][\"prev_adj_close\"],\n                                                          dfs[j][\"Adjusted Close\"] - dfs[j][\"prev_adj_close\"])\n                                                          .otherwise(0.0))\n        dfs[j] = dfs[j].withColumn(\"current_loss\", F.when(dfs[j][\"prev_adj_close\"] >= dfs[j][\"Adjusted Close\"],\n                                                         dfs[j][\"prev_adj_close\"] - dfs[j][\"Adjusted Close\"])\n                                                         .otherwise(0.0))\n        \n        # Adding temporary timestamp column\n        dfs[j] = dfs[j].withColumn('timestamp', dfs[j].Date.cast('timestamp'))\n        # Window of previous [period] days.\n        w = (Window().orderBy(F.col(\"timestamp\").cast('long')).rangeBetween(-period*86400, 0))\n        # Computing moving averages of day gain and day loss over the window\n        dfs[j] = dfs[j].withColumn(\n          \"smmau\",\n          F.avg(\"current_gain\").over(w)\n        )\n        \n        dfs[j] = dfs[j].withColumn(\n          \"smmad\",\n          F.avg(\"current_loss\").over(w)\n        )\n        \n        # Computing RSI given the moving averages\n        dfs[j] = dfs[j].withColumn(\"RSI\", F.when(dfs[j][\"smmau\"] == 0.0, 50.0).when(dfs[j][\"smmad\"] == 0.0, 50.0).otherwise(100 - (100/(1+(dfs[j][\"smmau\"]/dfs[j][\"smmad\"])))))            \n        # Adding overbought and oversold signals when the RSI goes above 70 and below 30\n        dfs[j] = dfs[j].withColumn(\"Overbought\", F.when(dfs[j][\"RSI\"] >= 70, 1.0).otherwise(0.0))\n        dfs[j] = dfs[j].withColumn(\"Oversold\", F.when(dfs[j][\"RSI\"] <= 30, 1.0).otherwise(0.0))\n        #dfs[j] = dfs[j].withColumn(\"Date\", dateCol)\n        \n        # Dropping temporary columns\n        dfs[j] = dfs[j].drop(\"prev_adj_close\", \"current_gain\", \"current_loss\", \"smmau\", \"smmad\", \"timestamp\")\n        \ndef fit_evaluate(\n  model_name: str,\n  window_size: int,\n  train_df: pyspark.sql.DataFrame,\n  test_df: pyspark.sql.DataFrame\n) -> None:\n  ''' Fits a model on train data and evaluate on test data. '''\n  features = [f'x_{time_step}' for time_step in range(window_size)]\n  train_df = train_df.withColumn('x', F.concat(*features)).drop(*features)\n  test_df = test_df.withColumn('x', F.concat(*features)).drop(*features)\n  \n  list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n  train_df_x = list_to_vector_udf(train_df['x']).alias('x')\n  test_df_x = list_to_vector_udf(test_df['x']).alias('x')\n  \n  train_df = train_df.select(train_df_x, train_df['y'])\n  test_df = test_df.select(test_df_x, test_df['y'])\n  if model_name == 'RandomForestRegressor':\n    _model = RandomForestRegressor(featuresCol='x', labelCol='y')\n  elif model_name == 'DecisionTreeRegressor':\n    _model = DecisionTreeRegressor(featuresCol='x', labelCol='y')\n\n  model = _model.fit(train_df)\n  \n  predicted_values = model.transform(test_df)\n  evaluator = RegressionEvaluator(labelCol=\"y\", predictionCol=\"prediction\", metricName=\"r2\")\n  r2 = evaluator.setMetricName('r2').evaluate(predicted_values)\n  mse = evaluator.setMetricName('mse').evaluate(predicted_values)\n  \n  print(f'Performance with {model_name}')\n  print('R2: {:.3f}, MSE: {:.3f}'.format(r2, mse))\n  \n  return predicted_values\n\ndef evaluate_trading_strategy_ps(\n  predicted_values: pyspark.sql.DataFrame,\n  features: List[str],\n  hparams: HParams,\n  price_std: float,\n  price_mean: float,\n  target_feature: str = 'Adjusted_Close'\n) -> None:\n  ''' Evaluate the trading strategy of PySpark models given their predictions. '''\n  target_idx = features.index(target_feature)\n  preds = predicted_values.collect()\n  X, y, y_pred = map(np.array, zip(*preds))\n  X = X.reshape(-1, hparams.window_size, hparams.input_dim)\n\n  pnl = 0.0\n  correct = 0\n  tries = 0\n  X[:, :, target_idx] = X[:, :, target_idx] * price_std + price_mean\n  y_pred = y_pred * price_std + price_mean\n  y = y * price_std + price_mean\n  for i in range(X.shape[0]):\n    # Increase predicted\n    current_price = X[i, -1, target_idx]\n    ret = 0.0\n    if current_price < y_pred[i]:\n      # Adding long profit / loss\n      ret = (y[i] - current_price) / current_price\n\n      pnl += ret\n      # Counting correct operations \n      tries += 1\n      correct += 1 if ret >= 0 else 0\n\n  print(f\"1-year profit: {(pnl.item())*100}%\")\n  print(f\"Operation accuracy: {(correct/tries)*100}%\")\n\n@torch.no_grad()\ndef evaluate_trading_strategy(\n  model: nn.Module,\n  test_dataloader: DataLoader,\n  mean: float,\n  std: float,\n  stock_num: int,\n  target_idx: int = -1\n) -> None:\n  pnl = 0.0\n  tries = 0\n  correct = 0\n  for X, y in test_dataloader:\n    y_pred = model(X.float())\n    # Re-adding mean to prices to make them positive\n    X[:, :, target_idx] = X[:, :, target_idx] * std + mean\n    y_pred = y_pred * std + mean\n    y = y * std + mean\n    for i in range(X.shape[0]):\n      # Increase predicted\n      current_price = X[i, -1, target_idx]\n      ret = 0.0\n      if current_price < y_pred[i]:\n        # Adding long profit / loss\n        ret = (y[i] - current_price) / current_price\n        \n        pnl += ret\n        # Counting correct operations \n        tries += 1\n        correct += 1 if ret >= 0 else 0\n\n  print(f\"1-year profit: {(pnl)*100}%\")\n  print(f\"Operation accuracy: {(correct/tries)*100}%\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de4a5d87-ba54-4970-8ecb-54e9ad305164"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"Overview of the missing values in the key_stats dataframe\\n\")\nkey_stats_summary = missing_values_summary(key_stats_df)\nkey_stats_summary"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9a201af9-db34-4924-81d9-4982833e72e1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Overview of the missing values in the key_stats dataframe\n\nOut[9]: Row(Date=0.0, Ticker=0.0, Price=2.326, DE Ratio=17.674, Trailing P/E=0.93, Price/Sales=0.0, Price/Book=0.465, Profit Margin=0.0, Operating Margin=0.0, Return on Assets=1.86, Return on Equity=1.86, Revenue Per Share=0.0, Market Cap=0.0, Enterprise Value=1.395, Forward P/E=40.465, PEG Ratio=0.0, Enterprise Value/Revenue=1.395, Enterprise Value/EBITDA=3.256, Revenue=1.395, Gross Profit=0.465, EBITDA=2.791, Net Income Avl to Common =0.0, Diluted EPS=0.465, Earnings Growth=5.116, Revenue Growth=3.256, Total Cash=0.465, Total Cash Per Share=0.465, Total Debt=8.372, Current Ratio=9.302, Book Value Per Share=0.93, Cash Flow=10.233, Beta=2.791)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Overview of the missing values in the key_stats dataframe\n\nOut[9]: Row(Date=0.0, Ticker=0.0, Price=2.326, DE Ratio=17.674, Trailing P/E=0.93, Price/Sales=0.0, Price/Book=0.465, Profit Margin=0.0, Operating Margin=0.0, Return on Assets=1.86, Return on Equity=1.86, Revenue Per Share=0.0, Market Cap=0.0, Enterprise Value=1.395, Forward P/E=40.465, PEG Ratio=0.0, Enterprise Value/Revenue=1.395, Enterprise Value/EBITDA=3.256, Revenue=1.395, Gross Profit=0.465, EBITDA=2.791, Net Income Avl to Common =0.0, Diluted EPS=0.465, Earnings Growth=5.116, Revenue Growth=3.256, Total Cash=0.465, Total Cash Per Share=0.465, Total Debt=8.372, Current Ratio=9.302, Book Value Per Share=0.93, Cash Flow=10.233, Beta=2.791)</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Missing values imputation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db3487d2-05a9-43f2-a9d0-1feb1ece31f9"}}},{"cell_type":"code","source":["summary = prices_df_nan_summary(prices_dfs, dfs_names)\npx.bar(summary, x='Stock name', y='Missing data (%)', hover_data=['Count'], title=\"Stock price dataset before preprocessing (only columns with missing values are displayed)\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c77cdd70-d8af-43db-b097-f9ce91f1c266"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\rGenerating prices summary ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rGenerating prices summary ...:  20%|██        | 1/5 [00:02&lt;00:08,  2.20s/it]\rGenerating prices summary ...:  40%|████      | 2/5 [00:03&lt;00:04,  1.62s/it]\rGenerating prices summary ...:  60%|██████    | 3/5 [00:04&lt;00:02,  1.32s/it]\rGenerating prices summary ...:  80%|████████  | 4/5 [00:05&lt;00:01,  1.15s/it]\rGenerating prices summary ...: 100%|██████████| 5/5 [00:06&lt;00:00,  1.02s/it]\rGenerating prices summary ...: 100%|██████████| 5/5 [00:06&lt;00:00,  1.21s/it]\nOut[10]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\rGenerating prices summary ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rGenerating prices summary ...:  20%|██        | 1/5 [00:02&lt;00:08,  2.20s/it]\rGenerating prices summary ...:  40%|████      | 2/5 [00:03&lt;00:04,  1.62s/it]\rGenerating prices summary ...:  60%|██████    | 3/5 [00:04&lt;00:02,  1.32s/it]\rGenerating prices summary ...:  80%|████████  | 4/5 [00:05&lt;00:01,  1.15s/it]\rGenerating prices summary ...: 100%|██████████| 5/5 [00:06&lt;00:00,  1.02s/it]\rGenerating prices summary ...: 100%|██████████| 5/5 [00:06&lt;00:00,  1.21s/it]\nOut[10]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"24bbb638-f334-428e-8413-340d01ff4b44\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"24bbb638-f334-428e-8413-340d01ff4b44\")) {                    Plotly.newPlot(                        \"24bbb638-f334-428e-8413-340d01ff4b44\",                        [{\"alignmentgroup\": \"True\", \"customdata\": [[1]], \"hovertemplate\": \"Stock name=%{x}<br>Missing data (%)=%{y}<br>Count=%{customdata[0]}<extra></extra>\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\"}, \"name\": \"\", \"offsetgroup\": \"\", \"orientation\": \"v\", \"showlegend\": false, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"AAPL\"], \"xaxis\": \"x\", \"y\": [0.01], \"yaxis\": \"y\"}],                        {\"barmode\": \"relative\", \"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Stock price dataset before preprocessing (only columns with missing values are displayed)\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Stock name\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Missing data (%)\"}}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"24bbb638-f334-428e-8413-340d01ff4b44\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"24bbb638-f334-428e-8413-340d01ff4b44\")) {                    Plotly.newPlot(                        \"24bbb638-f334-428e-8413-340d01ff4b44\",                        [{\"alignmentgroup\": \"True\", \"customdata\": [[1]], \"hovertemplate\": \"Stock name=%{x}<br>Missing data (%)=%{y}<br>Count=%{customdata[0]}<extra></extra>\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\"}, \"name\": \"\", \"offsetgroup\": \"\", \"orientation\": \"v\", \"showlegend\": false, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"AAPL\"], \"xaxis\": \"x\", \"y\": [0.01], \"yaxis\": \"y\"}],                        {\"barmode\": \"relative\", \"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Stock price dataset before preprocessing (only columns with missing values are displayed)\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Stock name\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Missing data (%)\"}}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>"]}}],"execution_count":0},{"cell_type":"markdown","source":["For most of the above stocks with missing values, we noticed that they indeed exist up to a given time and after that no more data is available. It may due to a business failure, hence no more stocks will be exchanged from that moment on."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"46156c58-76a8-40c8-88a3-b4bf0a800dd5"}}},{"cell_type":"code","source":["# Clear our input data from training NaN values\nprices_dfs_new = [remove_trailing_nan(df,name) for df,name in tqdm(zip(prices_dfs, dfs_names), total=len(prices_dfs), desc='Removing trailing NaN values ...')]\n\nsummary = prices_df_nan_summary(prices_dfs_new, dfs_names)\npx.bar(summary, x='Stock name', y='Missing data (%)', hover_data=['Count'], title=\"Stock price dataset after preprocessing (only columns with missing values are displayed)\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5884e89a-4386-4042-bd50-39dd70e3cef8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\rRemoving trailing NaN values ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rRemoving trailing NaN values ...:  20%|██        | 1/5 [00:04&lt;00:16,  4.08s/it]\rRemoving trailing NaN values ...:  40%|████      | 2/5 [00:06&lt;00:09,  3.09s/it]\rRemoving trailing NaN values ...:  60%|██████    | 3/5 [00:08&lt;00:05,  2.61s/it]\rRemoving trailing NaN values ...:  80%|████████  | 4/5 [00:10&lt;00:02,  2.43s/it]\rRemoving trailing NaN values ...: 100%|██████████| 5/5 [00:12&lt;00:00,  2.34s/it]\rRemoving trailing NaN values ...: 100%|██████████| 5/5 [00:12&lt;00:00,  2.57s/it]\n\rGenerating prices summary ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rGenerating prices summary ...:  20%|██        | 1/5 [00:03&lt;00:15,  3.81s/it]\rGenerating prices summary ...:  40%|████      | 2/5 [00:05&lt;00:08,  2.71s/it]\rGenerating prices summary ...:  60%|██████    | 3/5 [00:07&lt;00:04,  2.23s/it]\rGenerating prices summary ...:  80%|████████  | 4/5 [00:09&lt;00:02,  2.02s/it]\rGenerating prices summary ...: 100%|██████████| 5/5 [00:10&lt;00:00,  1.93s/it]\rGenerating prices summary ...: 100%|██████████| 5/5 [00:10&lt;00:00,  2.18s/it]\nOut[11]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\rRemoving trailing NaN values ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rRemoving trailing NaN values ...:  20%|██        | 1/5 [00:04&lt;00:16,  4.08s/it]\rRemoving trailing NaN values ...:  40%|████      | 2/5 [00:06&lt;00:09,  3.09s/it]\rRemoving trailing NaN values ...:  60%|██████    | 3/5 [00:08&lt;00:05,  2.61s/it]\rRemoving trailing NaN values ...:  80%|████████  | 4/5 [00:10&lt;00:02,  2.43s/it]\rRemoving trailing NaN values ...: 100%|██████████| 5/5 [00:12&lt;00:00,  2.34s/it]\rRemoving trailing NaN values ...: 100%|██████████| 5/5 [00:12&lt;00:00,  2.57s/it]\n\rGenerating prices summary ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rGenerating prices summary ...:  20%|██        | 1/5 [00:03&lt;00:15,  3.81s/it]\rGenerating prices summary ...:  40%|████      | 2/5 [00:05&lt;00:08,  2.71s/it]\rGenerating prices summary ...:  60%|██████    | 3/5 [00:07&lt;00:04,  2.23s/it]\rGenerating prices summary ...:  80%|████████  | 4/5 [00:09&lt;00:02,  2.02s/it]\rGenerating prices summary ...: 100%|██████████| 5/5 [00:10&lt;00:00,  1.93s/it]\rGenerating prices summary ...: 100%|██████████| 5/5 [00:10&lt;00:00,  2.18s/it]\nOut[11]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"c3eb2012-9eb5-4221-a4d8-f5f9509c60f8\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c3eb2012-9eb5-4221-a4d8-f5f9509c60f8\")) {                    Plotly.newPlot(                        \"c3eb2012-9eb5-4221-a4d8-f5f9509c60f8\",                        [{\"alignmentgroup\": \"True\", \"customdata\": [[1]], \"hovertemplate\": \"Stock name=%{x}<br>Missing data (%)=%{y}<br>Count=%{customdata[0]}<extra></extra>\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\"}, \"name\": \"\", \"offsetgroup\": \"\", \"orientation\": \"v\", \"showlegend\": false, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"AAPL\"], \"xaxis\": \"x\", \"y\": [0.01], \"yaxis\": \"y\"}],                        {\"barmode\": \"relative\", \"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Stock price dataset after preprocessing (only columns with missing values are displayed)\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Stock name\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Missing data (%)\"}}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"c3eb2012-9eb5-4221-a4d8-f5f9509c60f8\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c3eb2012-9eb5-4221-a4d8-f5f9509c60f8\")) {                    Plotly.newPlot(                        \"c3eb2012-9eb5-4221-a4d8-f5f9509c60f8\",                        [{\"alignmentgroup\": \"True\", \"customdata\": [[1]], \"hovertemplate\": \"Stock name=%{x}<br>Missing data (%)=%{y}<br>Count=%{customdata[0]}<extra></extra>\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\"}, \"name\": \"\", \"offsetgroup\": \"\", \"orientation\": \"v\", \"showlegend\": false, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"AAPL\"], \"xaxis\": \"x\", \"y\": [0.01], \"yaxis\": \"y\"}],                        {\"barmode\": \"relative\", \"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Stock price dataset after preprocessing (only columns with missing values are displayed)\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Stock name\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Missing data (%)\"}}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>"]}}],"execution_count":0},{"cell_type":"markdown","source":["At this point we use the fast forward imputation technique to fill-in missing values. Please note that in this case missing values are mostly due to holidays or periods when stocks are not exchanged."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b219a552-fd13-453f-826c-71fb94bfd81f"}}},{"cell_type":"markdown","source":["## Hyperparameters"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c47e3765-14b1-4228-a3b8-51985f53cd14"}}},{"cell_type":"code","source":["@dataclasses.dataclass\nclass HParams:\n  input_dim: int = -1  # Denoted by data transformations\n  window_size: int = 10\n  batch_size: int = 1024\n  features: int = -1  # Denoted by data transformations\n  hidden_dim: int = 128\n  num_layers: int = 1\n  dropout: int = 0.5\n  lr: int = 0.1\n    \nhparams = HParams()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0fb8282-de11-4c4a-86ba-39b556d9b988"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Building our new dataset"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3595c39e-c759-41d4-a927-ab75e577b16e"}}},{"cell_type":"code","source":["# Impute missing values in the prices dataset (i.e. fast-forward last valid values)\nprices_dfs_new, key_stats_df_new = impute_missing_values(prices_dfs_new, key_stats_df)\n\n# Merge the stock price dataset with fundamental data of the relative company\naggregate_dfs = merge_prices_fundamentals(prices_dfs_new, key_stats_df_new, dfs_names)\n\n# Fill gaps from the original dataset\ndfs = fill_missing_days(aggregate_dfs)\n                  \n# Add SMA indicator to each dataframe\nadd_sma(dfs)\n\n# Add RSI indicator to each dataframe\nadd_rsi(dfs)\n\n# Scale numerical features\nprice_mean, price_std = scale_features(dfs)\n\n# Create train/dev/test splits\ntrain_ds, val_ds, test_ds, features = from_dfs(dfs, window_size=hparams.window_size)\nhparams.input_dim = len(features)\nhparams.features = features"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b215510b-4ef8-4b04-b097-c467153c4c84"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\rMerging the datasets ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rMerging the datasets ...:  20%|██        | 1/5 [00:00&lt;00:01,  3.59it/s]\rMerging the datasets ...:  40%|████      | 2/5 [00:00&lt;00:00,  4.81it/s]\rMerging the datasets ...:  60%|██████    | 3/5 [00:00&lt;00:00,  4.77it/s]\rMerging the datasets ...:  80%|████████  | 4/5 [00:00&lt;00:00,  5.35it/s]\rMerging the datasets ...: 100%|██████████| 5/5 [00:00&lt;00:00,  6.16it/s]\rMerging the datasets ...: 100%|██████████| 5/5 [00:00&lt;00:00,  5.43it/s]\n\rFilling missing days ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFilling missing days ...:  20%|██        | 1/5 [00:06&lt;00:25,  6.42s/it]\rFilling missing days ...:  40%|████      | 2/5 [00:12&lt;00:18,  6.14s/it]\rFilling missing days ...:  60%|██████    | 3/5 [00:16&lt;00:10,  5.21s/it]\rFilling missing days ...:  80%|████████  | 4/5 [00:20&lt;00:04,  4.64s/it]\rFilling missing days ...: 100%|██████████| 5/5 [00:24&lt;00:00,  4.58s/it]\rFilling missing days ...: 100%|██████████| 5/5 [00:24&lt;00:00,  4.94s/it]\n\rAdding SMA ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rAdding SMA ...:  40%|████      | 2/5 [00:00&lt;00:00, 10.62it/s]\rAdding SMA ...:  80%|████████  | 4/5 [00:00&lt;00:00, 14.56it/s]\rAdding SMA ...: 100%|██████████| 5/5 [00:00&lt;00:00, 14.69it/s]\n\rAdding RSI ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rAdding RSI ...:  20%|██        | 1/5 [00:00&lt;00:02,  1.77it/s]\rAdding RSI ...:  40%|████      | 2/5 [00:00&lt;00:01,  2.14it/s]\rAdding RSI ...:  60%|██████    | 3/5 [00:01&lt;00:00,  2.35it/s]\rAdding RSI ...:  80%|████████  | 4/5 [00:01&lt;00:00,  2.56it/s]\rAdding RSI ...: 100%|██████████| 5/5 [00:02&lt;00:00,  2.60it/s]\rAdding RSI ...: 100%|██████████| 5/5 [00:02&lt;00:00,  2.43it/s]\n\rPerforming dfs union ...:   0%|          | 0/4 [00:00&lt;?, ?it/s]\rPerforming dfs union ...: 100%|██████████| 4/4 [00:00&lt;00:00, 18.70it/s]\rPerforming dfs union ...: 100%|██████████| 4/4 [00:00&lt;00:00, 18.66it/s]\n\rScaling numerical features ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rScaling numerical features ...:  20%|██        | 1/5 [00:01&lt;00:06,  1.60s/it]\rScaling numerical features ...:  40%|████      | 2/5 [00:02&lt;00:03,  1.21s/it]\rScaling numerical features ...:  60%|██████    | 3/5 [00:03&lt;00:02,  1.01s/it]\rScaling numerical features ...:  80%|████████  | 4/5 [00:04&lt;00:00,  1.04it/s]\rScaling numerical features ...: 100%|██████████| 5/5 [00:05&lt;00:00,  1.05it/s]\rScaling numerical features ...: 100%|██████████| 5/5 [00:05&lt;00:00,  1.03s/it]\n\rLoading dataset from dfs ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rLoading dataset from dfs ...:  20%|██        | 1/5 [00:20&lt;01:21, 20.46s/it]\rLoading dataset from dfs ...:  40%|████      | 2/5 [00:33&lt;00:48, 16.22s/it]\rLoading dataset from dfs ...:  60%|██████    | 3/5 [00:46&lt;00:29, 14.73s/it]\rLoading dataset from dfs ...:  80%|████████  | 4/5 [01:01&lt;00:14, 14.92s/it]\rLoading dataset from dfs ...: 100%|██████████| 5/5 [01:14&lt;00:00, 14.27s/it]\rLoading dataset from dfs ...: 100%|██████████| 5/5 [01:14&lt;00:00, 15.00s/it]\n\rCreating timesteps ...:   0%|          | 0/10 [00:00&lt;?, ?it/s]\rCreating timesteps ...:  10%|█         | 1/10 [00:03&lt;00:28,  3.17s/it]\rCreating timesteps ...:  20%|██        | 2/10 [00:06&lt;00:24,  3.11s/it]\rCreating timesteps ...:  30%|███       | 3/10 [00:09&lt;00:21,  3.00s/it]\rCreating timesteps ...:  40%|████      | 4/10 [00:12&lt;00:18,  3.01s/it]\rCreating timesteps ...:  50%|█████     | 5/10 [00:14&lt;00:14,  2.92s/it]\rCreating timesteps ...:  60%|██████    | 6/10 [00:17&lt;00:11,  2.88s/it]\rCreating timesteps ...:  70%|███████   | 7/10 [00:20&lt;00:08,  2.84s/it]\rCreating timesteps ...:  80%|████████  | 8/10 [00:23&lt;00:05,  2.83s/it]\rCreating timesteps ...:  90%|█████████ | 9/10 [00:26&lt;00:03,  3.10s/it]\rCreating timesteps ...: 100%|██████████| 10/10 [00:30&lt;00:00,  3.09s/it]\rCreating timesteps ...: 100%|██████████| 10/10 [00:30&lt;00:00,  3.00s/it]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\rMerging the datasets ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rMerging the datasets ...:  20%|██        | 1/5 [00:00&lt;00:01,  3.59it/s]\rMerging the datasets ...:  40%|████      | 2/5 [00:00&lt;00:00,  4.81it/s]\rMerging the datasets ...:  60%|██████    | 3/5 [00:00&lt;00:00,  4.77it/s]\rMerging the datasets ...:  80%|████████  | 4/5 [00:00&lt;00:00,  5.35it/s]\rMerging the datasets ...: 100%|██████████| 5/5 [00:00&lt;00:00,  6.16it/s]\rMerging the datasets ...: 100%|██████████| 5/5 [00:00&lt;00:00,  5.43it/s]\n\rFilling missing days ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rFilling missing days ...:  20%|██        | 1/5 [00:06&lt;00:25,  6.42s/it]\rFilling missing days ...:  40%|████      | 2/5 [00:12&lt;00:18,  6.14s/it]\rFilling missing days ...:  60%|██████    | 3/5 [00:16&lt;00:10,  5.21s/it]\rFilling missing days ...:  80%|████████  | 4/5 [00:20&lt;00:04,  4.64s/it]\rFilling missing days ...: 100%|██████████| 5/5 [00:24&lt;00:00,  4.58s/it]\rFilling missing days ...: 100%|██████████| 5/5 [00:24&lt;00:00,  4.94s/it]\n\rAdding SMA ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rAdding SMA ...:  40%|████      | 2/5 [00:00&lt;00:00, 10.62it/s]\rAdding SMA ...:  80%|████████  | 4/5 [00:00&lt;00:00, 14.56it/s]\rAdding SMA ...: 100%|██████████| 5/5 [00:00&lt;00:00, 14.69it/s]\n\rAdding RSI ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rAdding RSI ...:  20%|██        | 1/5 [00:00&lt;00:02,  1.77it/s]\rAdding RSI ...:  40%|████      | 2/5 [00:00&lt;00:01,  2.14it/s]\rAdding RSI ...:  60%|██████    | 3/5 [00:01&lt;00:00,  2.35it/s]\rAdding RSI ...:  80%|████████  | 4/5 [00:01&lt;00:00,  2.56it/s]\rAdding RSI ...: 100%|██████████| 5/5 [00:02&lt;00:00,  2.60it/s]\rAdding RSI ...: 100%|██████████| 5/5 [00:02&lt;00:00,  2.43it/s]\n\rPerforming dfs union ...:   0%|          | 0/4 [00:00&lt;?, ?it/s]\rPerforming dfs union ...: 100%|██████████| 4/4 [00:00&lt;00:00, 18.70it/s]\rPerforming dfs union ...: 100%|██████████| 4/4 [00:00&lt;00:00, 18.66it/s]\n\rScaling numerical features ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rScaling numerical features ...:  20%|██        | 1/5 [00:01&lt;00:06,  1.60s/it]\rScaling numerical features ...:  40%|████      | 2/5 [00:02&lt;00:03,  1.21s/it]\rScaling numerical features ...:  60%|██████    | 3/5 [00:03&lt;00:02,  1.01s/it]\rScaling numerical features ...:  80%|████████  | 4/5 [00:04&lt;00:00,  1.04it/s]\rScaling numerical features ...: 100%|██████████| 5/5 [00:05&lt;00:00,  1.05it/s]\rScaling numerical features ...: 100%|██████████| 5/5 [00:05&lt;00:00,  1.03s/it]\n\rLoading dataset from dfs ...:   0%|          | 0/5 [00:00&lt;?, ?it/s]\rLoading dataset from dfs ...:  20%|██        | 1/5 [00:20&lt;01:21, 20.46s/it]\rLoading dataset from dfs ...:  40%|████      | 2/5 [00:33&lt;00:48, 16.22s/it]\rLoading dataset from dfs ...:  60%|██████    | 3/5 [00:46&lt;00:29, 14.73s/it]\rLoading dataset from dfs ...:  80%|████████  | 4/5 [01:01&lt;00:14, 14.92s/it]\rLoading dataset from dfs ...: 100%|██████████| 5/5 [01:14&lt;00:00, 14.27s/it]\rLoading dataset from dfs ...: 100%|██████████| 5/5 [01:14&lt;00:00, 15.00s/it]\n\rCreating timesteps ...:   0%|          | 0/10 [00:00&lt;?, ?it/s]\rCreating timesteps ...:  10%|█         | 1/10 [00:03&lt;00:28,  3.17s/it]\rCreating timesteps ...:  20%|██        | 2/10 [00:06&lt;00:24,  3.11s/it]\rCreating timesteps ...:  30%|███       | 3/10 [00:09&lt;00:21,  3.00s/it]\rCreating timesteps ...:  40%|████      | 4/10 [00:12&lt;00:18,  3.01s/it]\rCreating timesteps ...:  50%|█████     | 5/10 [00:14&lt;00:14,  2.92s/it]\rCreating timesteps ...:  60%|██████    | 6/10 [00:17&lt;00:11,  2.88s/it]\rCreating timesteps ...:  70%|███████   | 7/10 [00:20&lt;00:08,  2.84s/it]\rCreating timesteps ...:  80%|████████  | 8/10 [00:23&lt;00:05,  2.83s/it]\rCreating timesteps ...:  90%|█████████ | 9/10 [00:26&lt;00:03,  3.10s/it]\rCreating timesteps ...: 100%|██████████| 10/10 [00:30&lt;00:00,  3.09s/it]\rCreating timesteps ...: 100%|██████████| 10/10 [00:30&lt;00:00,  3.00s/it]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##Models definition"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b15deec7-b5a2-49db-a08d-94bd3145ed1c"}}},{"cell_type":"code","source":["class SimpleLSTM(nn.Module):\n  def __init__(self, hparams):\n      super().__init__()\n      self.hparams = hparams\n      self.lstm = nn.LSTM(hparams.input_dim, hparams.hidden_dim, num_layers=hparams.num_layers, batch_first=True)\n      self.fc1 = nn.Linear(hparams.hidden_dim, hparams.hidden_dim//2)\n      self.fc2 = nn.Linear(hparams.hidden_dim//2, 1)\n      self.dropout = nn.Dropout(hparams.dropout)\n\n  def forward(self, x: np.ndarray):\n      x, (h,c) = self.lstm(x)\n      x = torch.relu(self.fc1(x[:,-1]))\n      x = self.fc2(x)\n      return x.squeeze()\n\ndef train(\n  model: nn.Module,\n  optimizer: torch.optim.SGD,\n  train_dataloader: DataLoader,\n  valid_dataloader: DataLoader,\n  logger,\n  epochs: int = 5\n) -> None:\n  train_history = []\n  valid_history = []\n  mean_r2 = 0.0\n  mean_adjusted_r2 = 0.0\n  best_r2 = 0\n  best_adj_r2 = 0\n  model_state = model.state_dict().copy()\n  best_epoch = 0\n\n  progress = tqdm(range(epochs))\n  progress.set_description(f\"Epoch: {0}, train loss: 0, val loss: 0\")\n  for epoch in progress:\n      losses = []\n      r2_ls = []\n      adjusted_r2_ls = []\n\n      for x, y in train_dataloader:\n          # Zero the gradients to prevent Pytorch from accumulating the gradients\n          optimizer.zero_grad()\n          y_hat = model(x.float())\n\n          # Compute the loss\n          loss = loss_fn(y_hat, y.float())\n          losses.append(loss)\n\n          # Compute the gradient of the loss and update model parameters\n          loss.backward()\n          optimizer.step()\n\n      mean_loss = sum(losses) / len(losses)\n      train_history.append(mean_loss.item())\n\n      losses = []\n      with torch.no_grad():\n          for x, y in valid_dataloader:\n              y_hat = model(x.float())\n              loss = loss_fn(y_hat, y.float())\n              losses.append(loss)\n              r2_ls.append(r2_score(y_hat, y))\n              adjusted_r2_ls.append(adjusted_r2_score(y_hat, y, x.shape[1] * x.shape[2]))\n\n      mean_loss = sum(losses) / len(losses)\n      valid_history.append(mean_loss.item())\n      mean_r2 = sum(r2_ls) / len(r2_ls)\n      mean_adjusted_r2 = sum(adjusted_r2_ls) / len(adjusted_r2_ls)\n      \n      if mean_adjusted_r2 > best_adj_r2:\n          #print(f'\\nCurrent best is {mean_adjusted_r2}')\n          best_adj_r2 = mean_adjusted_r2\n          best_r2 = mean_r2\n          model_state = model.state_dict().copy()\n          best_epoch = epoch\n      \n      logger.log(\n        {\n          'train_loss': train_history[-1],\n          'valid_loss': valid_history[-1],\n          'r2': mean_r2,\n          'adjusted_r2': mean_adjusted_r2,\n        }\n      )\n      \n      progress.set_description(f\"Epoch: {epoch+1}, train loss: {train_history[-1]}, val loss: {valid_history[-1]}\")\n      \n  # Select the model with the best overall performances\n  model.load_state_dict(model_state)\n  print(f'Saving the parameters of the best model at epoch {best_epoch}')\n\n  return {\n      'train_history': train_history,\n      'valid_history': valid_history,\n      'r2': best_r2,\n      'adj_r2': best_adj_r2\n  }\n\n@torch.no_grad()\ndef evaluate(model, dataloader):\n    Y = []\n    Y_pred = []\n\n    for x, y in dataloader:\n        y_hat = model(x.float())\n        Y.append(y)\n        Y_pred.append(y_hat)\n\n    return {\n        'y_true': torch.stack(Y).reshape(-1),\n        'y_pred': torch.stack(Y_pred).reshape(-1).round()\n    }"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"92ce704a-ec3c-43f9-b503-6fc7bf2aaa65"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##Model training"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"355d5de2-0b6f-4273-8df9-1cd3ca813f90"}}},{"cell_type":"code","source":["# Define the number of epochs to run the model on\nhparams.epochs = 100\nhparams.lr = 0.01\nhparams.dropout = 0.0\nhparams.momentum = 0.3\n\n# Configure the current run\nrun = wandb.init(reinit=True, project='distributed_spf', config=hparams)\n\n# Define the loss function and the model's optimizer\nloss_fn = nn.MSELoss()\nmodel = SimpleLSTM(hparams)\noptimizer = torch.optim.SGD(model.parameters(), lr=hparams.lr, momentum=hparams.momentum)\n\n# Materialize spark dataframes to DBFS in parqet format\nconverter_train = make_spark_converter(train_ds)\nconverter_valid = make_spark_converter(val_ds)\nconverter_test = make_spark_converter(test_ds)\n\n# Fit the model on training data, and evaluate it on validation split\nwith converter_train.make_torch_dataloader(\n  batch_size=hparams.batch_size, data_loader_fn=partial(data_loader_fn, hparams.window_size), num_epochs=1\n) as train_dataloader, converter_valid.make_torch_dataloader(\n  batch_size=hparams.batch_size, data_loader_fn=partial(data_loader_fn, hparams.window_size), num_epochs=1\n) as valid_dataloader, converter_test.make_torch_dataloader(\n  batch_size=hparams.batch_size, data_loader_fn=partial(data_loader_fn, hparams.window_size), num_epochs=1\n) as test_dataloader:\n  \n  train_logs = train(model, optimizer, train_dataloader, valid_dataloader, run, epochs=hparams.epochs)\n  plot_loss_history(train_logs)\n  \n  evaluate_trading_strategy(model, test_dataloader, price_mean, price_std, len(dfs), target_idx=features.index('Adjusted_Close'))\n\n# Log the experiments\nrun.finish()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08c49aca-c864-49b2-9a5a-787531af03bd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##Evaluation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea6dff9f-d37a-4581-a7a7-6c705b08fb95"}}},{"cell_type":"code","source":["tree_predicted_values = fit_evaluate('DecisionTreeRegressor', hparams.window_size, train_ds, test_ds)\nevaluate_trading_strategy_ps(tree_predicted_values, features, hparams, price_std, price_mean)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"03eb7a62-7851-4c8d-9bdd-4328e09151d1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["rf_predicted_values = fit_evaluate('RandomForestRegressor', hparams.window_size, train_ds, test_ds)\nevaluate_trading_strategy_ps(rf_predicted_values, features, hparams, price_std, price_mean)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0388bb22-41e8-4f62-a3cd-a6bf6f6f2e5f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"dist_forecasting","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1881792650878518}},"nbformat":4,"nbformat_minor":0}
