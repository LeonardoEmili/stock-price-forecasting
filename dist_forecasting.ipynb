{"cells":[{"cell_type":"markdown","source":["## Import required packages"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e862fc71-84e1-4af7-badc-898efadd0bc5"}}},{"cell_type":"code","source":["# Download required packages\n!pip -q install gdown missingno torch petastorm wandb pytorch-lightning\n\n%matplotlib inline\n\nimport pyspark\nfrom pyspark.sql import *\nfrom pyspark.sql.types import *\nimport pyspark.sql.functions as F\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql.window import Window\n\nfrom petastorm.spark import SparkDatasetConverter, make_spark_converter\nfrom petastorm.pytorch import DataLoader\nspark.conf.set(SparkDatasetConverter.PARENT_CACHE_DIR_URL_CONF, 'file:///dbfs/tmp/petastorm/cache')\n\nimport pytorch_lightning as pl\npl.seed_everything(42)\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport missingno as msno\nimport torch\nimport re\nimport torch.nn as nn\nfrom typing import *\nimport datetime\nimport gdown\nimport dataclasses\nfrom operator import itemgetter\nfrom functools import partial\n\nimport wandb\nfrom pytorch_lightning.loggers import WandbLogger\nwandb.login(key='147339090e59f6a02bed0fa3f938a2b1ecbc567c')\n\nimport tqdm as tq\ndef tqdm(*args, **kwargs):\n  ''' Small trick to prevent tqdm printing newlines at each step. '''\n  return tq.tqdm(*args, **kwargs, leave=True, position=0)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d89c4672-97c1-49d3-9350-6008885da2ab"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"><span class=\"ansi-yellow-fg\">WARNING: You are using pip version 20.2.4; however, version 21.1.1 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\nGlobal seed set to 42\nwandb: W&amp;B API key is configured (use `wandb login --relogin` to force relogin)\nwandb: WARNING If you&#39;re specifying your api key in code, ensure this code is not shared publically.\nwandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\nwandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 20.2.4; however, version 21.1.1 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\nGlobal seed set to 42\nwandb: Currently logged in as: leonardoemili (use `wandb login --relogin` to force relogin)\nwandb: WARNING If you&#39;re specifying your api key in code, ensure this code is not shared publically.\nwandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\nwandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-yellow-fg\">WARNING: You are using pip version 20.2.4; however, version 21.1.1 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\nGlobal seed set to 42\nwandb: W&amp;B API key is configured (use `wandb login --relogin` to force relogin)\nwandb: WARNING If you&#39;re specifying your api key in code, ensure this code is not shared publically.\nwandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\nwandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n<span class=\"ansi-yellow-fg\">WARNING: You are using pip version 20.2.4; however, version 21.1.1 is available.\r\nYou should consider upgrading via the &#39;/databricks/python3/bin/python -m pip install --upgrade pip&#39; command.</span>\r\nGlobal seed set to 42\nwandb: Currently logged in as: leonardoemili (use `wandb login --relogin` to force relogin)\nwandb: WARNING If you&#39;re specifying your api key in code, ensure this code is not shared publically.\nwandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\nwandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Data aquisition\nWe retrieve our datasets and download them to a temporary directory in the driver node."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f76226d3-37ac-40d6-a417-a05ca05a7000"}}},{"cell_type":"code","source":["!rm -rf /tmp/data /tmp/__MACOSX\ngdown.download('https://drive.google.com/uc?id=1ggmDp-AWFzbQReLG0pLpQE_3fO0C0RnM', '/tmp/data.zip', quiet=False)\n!unzip -q /tmp/data.zip -d /tmp/\n!rm /tmp/data.zip"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c1efdeb-4084-4115-9920-536feac86d20"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Downloading...\nFrom: https://drive.google.com/uc?id=1ggmDp-AWFzbQReLG0pLpQE_3fO0C0RnM\nTo: /tmp/data.zip\n\r0.00B [00:00, ?B/s]\r4.72MB [00:00, 18.0MB/s]\r17.3MB [00:00, 33.2MB/s]\r25.7MB [00:00, 36.6MB/s]\r34.1MB [00:00, 38.3MB/s]\r42.5MB [00:01, 40.9MB/s]\r58.2MB [00:01, 63.7MB/s]\r66.6MB [00:01, 52.0MB/s]\r71.9MB [00:01, 47.7MB/s]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Downloading...\nFrom: https://drive.google.com/uc?id=1ggmDp-AWFzbQReLG0pLpQE_3fO0C0RnM\nTo: /tmp/data.zip\n\r0.00B [00:00, ?B/s]\r4.72MB [00:00, 18.0MB/s]\r17.3MB [00:00, 33.2MB/s]\r25.7MB [00:00, 36.6MB/s]\r34.1MB [00:00, 38.3MB/s]\r42.5MB [00:01, 40.9MB/s]\r58.2MB [00:01, 63.7MB/s]\r66.6MB [00:01, 52.0MB/s]\r71.9MB [00:01, 47.7MB/s]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Then we load the datasets to the DBFS."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"941ae011-778f-4659-9774-ff7df196b5b1"}}},{"cell_type":"code","source":["dbutils.fs.mv(\"file:/tmp/data\", \"dbfs:/data\", recurse=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"791fea85-d7b5-4432-b530-ddae393cc5d6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[3]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[3]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%fs ls /data/"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c18efa6b-4546-4cab-9e4b-582119acee64"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/data/.DS_Store",".DS_Store",6148],["dbfs:/data/key_stats_yahoo.csv","key_stats_yahoo.csv",2047081],["dbfs:/data/prices/","prices/",0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":[],"pivotAggregation":null,"xColumns":[],"yColumns":[]},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/data/.DS_Store</td><td>.DS_Store</td><td>6148</td></tr><tr><td>dbfs:/data/key_stats_yahoo.csv</td><td>key_stats_yahoo.csv</td><td>2047081</td></tr><tr><td>dbfs:/data/prices/</td><td>prices/</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%fs ls /data/"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5e7b9cc-713e-4303-a194-15a532c0757b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/data/.DS_Store",".DS_Store",6148],["dbfs:/data/key_stats_yahoo.csv","key_stats_yahoo.csv",2047081],["dbfs:/data/prices/","prices/",0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":[],"pivotAggregation":null,"xColumns":[],"yColumns":[]},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/data/.DS_Store</td><td>.DS_Store</td><td>6148</td></tr><tr><td>dbfs:/data/key_stats_yahoo.csv</td><td>key_stats_yahoo.csv</td><td>2047081</td></tr><tr><td>dbfs:/data/prices/</td><td>prices/</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Dataset loading"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"898c47b5-01c8-4a5c-86c1-58bd6334f04a"}}},{"cell_type":"code","source":["key_stats_df = spark.read.load(\"dbfs:/data/key_stats_yahoo.csv\", \n                           format=\"csv\",\n                           sep=\",\",\n                           inferSchema=\"true\",\n                           header=\"true\"\n                          )\n\n# Drop the first ID column\nkey_stats_df = sc.parallelize(key_stats_df.drop(key_stats_df.columns[0]).head(1005)).toDF()#TODO: remove head(n) (only meant for development)\n#key_stats_df = key_stats_df.drop(key_stats_df.columns[0])\nkey_stats_df.schema['Date'].nullable = False\n\n# Use legacy format to parse dates\nspark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\nkey_stats_df = key_stats_df.withColumn(\"Date\", F.to_date(key_stats_df[\"Date\"], 'MM/dd/yyyy HH:mm'))\n\n# Cast numerical columns to double\nfor column in key_stats_df.columns[2:]:\n  key_stats_df = key_stats_df.withColumn(column, key_stats_df[column].cast(\"double\"))\n\n# Prices dataframes for every stock #TODO: remove :N (only meant for development)\nprices_files = [f.path for f in dbutils.fs.ls('/data/prices/')[:10] if f.path.endswith('.csv')]\n#prices_files = [f.path for f in dbutils.fs.ls('/data/prices/') if f.path.endswith('.csv')]\ndfs_names = [f.rsplit('/', 1)[1][:-len('.csv')] for f in prices_files]\nprices_dfs = []\nfor f in tqdm(prices_files, desc='Reading stock price data', total=len(prices_files)):\n  df = spark.read.load(f,\n                       format=\"csv\",\n                       sep=\",\",\n                       inferSchema=\"true\",\n                       header=\"true\"\n                      )\n  df = df.withColumn(\"Date\", F.to_date(df[\"Date\"], 'dd-MM-yyyy'))\n  df.schema['Date'].nullable = False\n  prices_dfs.append(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"832ad8e5-1aed-43f4-8748-ec7a4ced09bd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\rReading stock price data:   0%|          | 0/9 [00:00&lt;?, ?it/s]\rReading stock price data:  11%|█         | 1/9 [00:01&lt;00:10,  1.37s/it]\rReading stock price data:  22%|██▏       | 2/9 [00:02&lt;00:09,  1.30s/it]\rReading stock price data:  33%|███▎      | 3/9 [00:03&lt;00:07,  1.19s/it]\rReading stock price data:  44%|████▍     | 4/9 [00:05&lt;00:06,  1.26s/it]\rReading stock price data:  56%|█████▌    | 5/9 [00:06&lt;00:04,  1.23s/it]\rReading stock price data:  67%|██████▋   | 6/9 [00:07&lt;00:03,  1.18s/it]\rReading stock price data:  78%|███████▊  | 7/9 [00:08&lt;00:02,  1.24s/it]\rReading stock price data:  89%|████████▉ | 8/9 [00:09&lt;00:01,  1.19s/it]\rReading stock price data: 100%|██████████| 9/9 [00:10&lt;00:00,  1.14s/it]\rReading stock price data: 100%|██████████| 9/9 [00:10&lt;00:00,  1.20s/it]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\rReading stock price data:   0%|          | 0/9 [00:00&lt;?, ?it/s]\rReading stock price data:  11%|█         | 1/9 [00:01&lt;00:10,  1.37s/it]\rReading stock price data:  22%|██▏       | 2/9 [00:02&lt;00:09,  1.30s/it]\rReading stock price data:  33%|███▎      | 3/9 [00:03&lt;00:07,  1.19s/it]\rReading stock price data:  44%|████▍     | 4/9 [00:05&lt;00:06,  1.26s/it]\rReading stock price data:  56%|█████▌    | 5/9 [00:06&lt;00:04,  1.23s/it]\rReading stock price data:  67%|██████▋   | 6/9 [00:07&lt;00:03,  1.18s/it]\rReading stock price data:  78%|███████▊  | 7/9 [00:08&lt;00:02,  1.24s/it]\rReading stock price data:  89%|████████▉ | 8/9 [00:09&lt;00:01,  1.19s/it]\rReading stock price data: 100%|██████████| 9/9 [00:10&lt;00:00,  1.14s/it]\rReading stock price data: 100%|██████████| 9/9 [00:10&lt;00:00,  1.20s/it]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Dataset analysis"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"be1bb73d-1713-4401-9ca9-cef3f47a976f"}}},{"cell_type":"code","source":["print(\"Prices dataframe format:\")\nprices_dfs[0].printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bd6040d0-f97c-4ef4-bd0d-3a1a8d4214a5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Prices dataframe format:\nroot\n |-- Date: date (nullable = true)\n |-- Low: double (nullable = true)\n |-- Open: double (nullable = true)\n |-- Volume: integer (nullable = true)\n |-- High: double (nullable = true)\n |-- Close: double (nullable = true)\n |-- Adjusted Close: double (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Prices dataframe format:\nroot\n-- Date: date (nullable = true)\n-- Low: double (nullable = true)\n-- Open: double (nullable = true)\n-- Volume: integer (nullable = true)\n-- High: double (nullable = true)\n-- Close: double (nullable = true)\n-- Adjusted Close: double (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"Key stats dataframe format:\")\nkey_stats_df.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc56a262-df2a-4a39-ab77-76f55ee2948c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Key stats dataframe format:\nroot\n |-- Date: date (nullable = true)\n |-- Ticker: string (nullable = true)\n |-- Price: double (nullable = true)\n |-- DE Ratio: double (nullable = true)\n |-- Trailing P/E: double (nullable = true)\n |-- Price/Sales: double (nullable = true)\n |-- Price/Book: double (nullable = true)\n |-- Profit Margin: double (nullable = true)\n |-- Operating Margin: double (nullable = true)\n |-- Return on Assets: double (nullable = true)\n |-- Return on Equity: double (nullable = true)\n |-- Revenue Per Share: double (nullable = true)\n |-- Market Cap: double (nullable = true)\n |-- Enterprise Value: double (nullable = true)\n |-- Forward P/E: double (nullable = true)\n |-- PEG Ratio: double (nullable = true)\n |-- Enterprise Value/Revenue: double (nullable = true)\n |-- Enterprise Value/EBITDA: double (nullable = true)\n |-- Revenue: double (nullable = true)\n |-- Gross Profit: double (nullable = true)\n |-- EBITDA: double (nullable = true)\n |-- Net Income Avl to Common : double (nullable = true)\n |-- Diluted EPS: double (nullable = true)\n |-- Earnings Growth: double (nullable = true)\n |-- Revenue Growth: double (nullable = true)\n |-- Total Cash: double (nullable = true)\n |-- Total Cash Per Share: double (nullable = true)\n |-- Total Debt: double (nullable = true)\n |-- Current Ratio: double (nullable = true)\n |-- Book Value Per Share: double (nullable = true)\n |-- Cash Flow: double (nullable = true)\n |-- Beta: double (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Key stats dataframe format:\nroot\n-- Date: date (nullable = true)\n-- Ticker: string (nullable = true)\n-- Price: double (nullable = true)\n-- DE Ratio: double (nullable = true)\n-- Trailing P/E: double (nullable = true)\n-- Price/Sales: double (nullable = true)\n-- Price/Book: double (nullable = true)\n-- Profit Margin: double (nullable = true)\n-- Operating Margin: double (nullable = true)\n-- Return on Assets: double (nullable = true)\n-- Return on Equity: double (nullable = true)\n-- Revenue Per Share: double (nullable = true)\n-- Market Cap: double (nullable = true)\n-- Enterprise Value: double (nullable = true)\n-- Forward P/E: double (nullable = true)\n-- PEG Ratio: double (nullable = true)\n-- Enterprise Value/Revenue: double (nullable = true)\n-- Enterprise Value/EBITDA: double (nullable = true)\n-- Revenue: double (nullable = true)\n-- Gross Profit: double (nullable = true)\n-- EBITDA: double (nullable = true)\n-- Net Income Avl to Common : double (nullable = true)\n-- Diluted EPS: double (nullable = true)\n-- Earnings Growth: double (nullable = true)\n-- Revenue Growth: double (nullable = true)\n-- Total Cash: double (nullable = true)\n-- Total Cash Per Share: double (nullable = true)\n-- Total Debt: double (nullable = true)\n-- Current Ratio: double (nullable = true)\n-- Book Value Per Share: double (nullable = true)\n-- Cash Flow: double (nullable = true)\n-- Beta: double (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Utility functions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"578db780-5427-4c43-8252-682b1a10c6d0"}}},{"cell_type":"code","source":["# TODO: add remaining utility functions\n\ndef prices_df_nan_summary(prices_dfs: List[pyspark.sql.DataFrame], names: List[str]) -> pd.DataFrame:\n  ''' Utility function to summarize columns that have missing values. '''\n  nan_dfs = []\n  for prices_df, name in tqdm(zip(prices_dfs, names), total=len(prices_dfs), desc='Generating prices summary ...'):\n    nan_absolute = prices_df.agg(*[F.count(F.when(F.isnull(c), c)).alias(c) for c in prices_df.columns]).first()\n    if any(nan_absolute):\n      # Simple conversion from Pyspark row -> Python set of values\n      values = set(nan_absolute.asDict().values()).difference({0})\n      # Either we don't have values for that row, or we have all of them (but Date which is non-nullable)\n      # Values contains the no. of NaN values and 0 in correspondance of the Date column\n      assert len(values) == 1\n      nan_count = values.pop()\n      nan_dfs.append((name, round(100*nan_count/prices_df.count(), 3), nan_count))\n\n  return pd.DataFrame(nan_dfs, columns=['Stock name', 'Missing data (%)', 'Count'])\n\ndef remove_trailing_nan(df: pyspark.sql.DataFrame, ticker: str, col: str = 'Low') -> pyspark.sql.DataFrame:\n  '''\n    A trick to detect if the input DataFrame ends with a contiguous collection of NaN rows, returns the dataframe without them.\n  '''\n  # The total number of rows of the dataframe\n  df_length = df.count()\n  \n  # Sort the input dataframe and add a new column to keep track of the relative position of each row\n  df_sorted_id = df.sort('Date').withColumn('id', F.row_number().over(Window.orderBy('Date')))\n  \n  # Tricky part here: create a new column called 'cumsum' that will store the progressive number of consecutive NaN in our dataset.\n  # Let's break it into smaller parts:\n  # 1) create an index generator that will partition by 'Low' values [(...,Null...), (...,value1,...), (...,value2...), ... (...)] and within rows order by date\n  # Example:\n  ## |2019-06-05|null|null|  null|null| null|          null|624|        21|\n  ## |2019-06-06|null|null|  null|null| null|          null|625|        22|\n  ## |2019-06-07|null|null|  null|null| null|          null|626|        23| <- last column is the cumulative sum (i.e. the number of consecutive NaN)\n  ## ...\n  ## |2019-05-09|23.2|11.5|   7.3|4.2|  16.2|          29.1|1  |         0|\n  ## |2019-05-10|23.2|11.5|   7.3|4.2|  16.2|          29.1|2  |         0|\n  # 2) assign to each row a progressive index starting from 1 if it has null in correspondance of Low, zero otherwise\n  # 3) store these values into a new column called cumsum (i.e. it behaves like pandas cumsum)\n  # 4) at the end, the row whose ID corresponds to the length of the dataframe will contain at column 'cumsum' the no. of trailing NaN values.\n  cumsum_df = df_sorted_id.withColumn('cumsum', F.when(F.isnull(df_sorted_id.Low), F.row_number().over(Window.partitionBy('Low').orderBy('Date'))).otherwise(0))\n\n  # Retrieve the \"last\" row and read the value of cumsum\n  end_idx = cumsum_df.where(cumsum_df['id'] == df_length).first().cumsum\n  \n  # Retain rows whose index is lower len(df) - end_idx + 1 (i.e. cut trailing NaN values)\n  return df_sorted_id.where(df_sorted_id['id'] <= df_length-end_idx+1)\n\n\ndef merge_prices_fundamentals(\n    prices_dfs: List[pyspark.sql.DataFrame],\n    key_stats_df: pyspark.sql.DataFrame,\n    dfs_names: List[str],\n    drop_cols: List[str] = ['Date', 'Ticker', 'Price']\n    ) -> List[pyspark.sql.DataFrame]:\n  # Define the target list of dataframes\n  prices_dfs_new = []\n  for ticker in tqdm(key_stats_df.select('Ticker').distinct().collect(), desc='Merging the datasets ...'):\n    ticker = ticker[0]\n    # Consider only stocks for which we have fundamental data\n    if ticker.upper() not in dfs_names: continue\n      \n    # The prices dataframe associated to the current ticker\n    prices_df_idx = dfs_names.index(ticker.upper())\n    prices_df = prices_dfs[prices_df_idx]\n    \n    # Retrieve financial reports for the current ticker\n    ticker_df = key_stats_df.filter(F.col('Ticker') == ticker)\n    \n    # Perform an inner join between the two dataframes, we first take all reports\n    # whose date is at most the prices date (then we will take the latest available)\n    joined_df = ticker_df.join(prices_df, ticker_df.Date <= prices_df.Date, how='inner')\n    \n    # Let's break this into smaller parts:\n    # 1) Add a new column for the date latest available report for that stock. To do that\n    #    we partition over **prices** Date using the Window object, and the the max over\n    #    **ticker** Date.\n    # 2) Retain those columns whose financial report date is the same as in ticker_df_max_date\n    # 3) Finally drop the **ticker** Date and other unused columns\n    joined_df = joined_df.withColumn('ticker_df_max_date', F.max(ticker_df['Date'])\\\n                      .over(Window.partitionBy(prices_df['Date'])))\\\n                      .where(ticker_df['Date'] == F.col('ticker_df_max_date'))\\\n                      .drop('ticker_df_max_date', 'High', 'Low', 'Open', 'Close')\\\n                      .drop(ticker_df['Date'])\\\n                      \n    # Return the usual list of dataframes\n    prices_dfs_new.append(joined_df)\n    \n  return prices_dfs_new\n    \n                \ndef fill_missing_days(\n  aggregate_dfs: List[pyspark.sql.DataFrame],\n  remove_weekends: bool = True,\n  end_date: str = '2014-01-01'\n) -> List[pyspark.sql.DataFrame]:\n  result_dfs = []\n  \n  @udf(\"boolean\")\n  def is_weekday(date: datetime) -> bool:\n      ''' Returns true if the provided date corresponds to a weekday. '''\n      return date.weekday() < 5\n    \n  for df in tqdm(aggregate_dfs, desc='Filling missing days ...'):\n    # In this case we apply the following steps in order to apply fill-forward to our dataset:\n    # 1) define a Window object the will over the dataset sorted with decreasing dates\n    # 2) compute the difference in days between consecutive rows (11/05/2021 - 07/05/2021 ==> 4 days)\n    #    and store it in a column named diff\n    # 3) compute an increasing index in the column seq that is the days gap we need to fill\n    # Example:\n    # |Date      | Adjusted close   |diff|seq|new_date  |\n    # |2021-04-09|116.80999755859375|   3|  1|2021-04-11|\n    # |2021-04-09|116.80999755859375|   3|  2|2021-04-10|\n    # |2021-04-09|116.80999755859375|   3|  3|2021-04-09|\n    # 4) create a new column new_date as the result of the computation F.col('Date') + F.col('diff') - F.col('seq')\n    # 5) only retain rows whose date is before the provided end_date\n    #\n    # N.B. if we want to bfill the values we should instead consider the dataframes with dates in ascending order,\n    # and subtract the value of F.col('diff') instead of summing it. Other parts of the code stays the same.\n    df = df\\\n    .withColumn('diff', F.datediff(F.lag(F.col('Date'),1).over(Window.orderBy(F.desc('Date'))), F.col('Date')))\\\n    .withColumn('seq', F.explode(F.sequence(F.lit(1), F.col(\"diff\"))))\\\n    .withColumn('new_date', (F.col('Date') + F.col('diff') - F.col('seq')))\\\n    .where(F.col('new_date') < pd.Timestamp(end_date))\n    \n    # If specified, remove weekends that are most likely created by us as synthetic data with the ffill technique\n    if remove_weekends:\n      df = df.where(is_weekday(F.col('new_date')))\n      \n    # Drop unecessary columns\n    df = df.drop('Date', 'diff', 'seq').withColumnRenamed('new_date', 'Date')\n    \n    # If the dataframe is actually non-empty, add it to the list of resulting dataframes\n    if df.count() > 0:\n      result_dfs.append(df)\n  return result_dfs\n\ndef missing_values_summary(df):\n  ''' Returns a utility summary to view missing values in our dataframe. '''\n  n = df.count()\n  \n  def to_percentage(x: pyspark.sql.column.Column, n: int) -> int:\n    ''' Utility function to compute the amount of missing values as a percentage of the original dataframe. '''\n    return F.round(100 * x / n, 3)\n  \n  # Aggregate using the count function over null values, and return a view over the obtained (single row) dataframe\n  return df.agg(*[to_percentage(F.count(F.when(F.isnull(c), c)), n).alias(c) for c in df.columns]).first()\n\ndef scale_features(dfs: List[pyspark.sql.DataFrame]) -> None:\n    ''' Scales the numerical features to unit variance. '''\n    \n    scalable_features = ['DE Ratio', 'Trailing P/E', 'Price/Sales', 'Price/Book',\n       'Profit Margin', 'Operating Margin', 'Return on Assets',\n       'Return on Equity', 'Revenue Per Share', 'Market Cap',\n       'Enterprise Value', 'PEG Ratio', 'Enterprise Value/Revenue',\n       'Enterprise Value/EBITDA', 'Revenue', 'Gross Profit', 'EBITDA',\n       'Net Income Avl to Common ', 'Diluted EPS', 'Earnings Growth',\n       'Revenue Growth', 'Total Cash', 'Total Cash Per Share', 'Total Debt',\n       'Current Ratio', 'Book Value Per Share', 'Cash Flow', 'Beta', 'Volume',\n       'Adjusted Close', 'SMA', 'RSI']\n    \n\n    aggregate_df = dfs[0]\n    for df in dfs[1:]:\n      aggregate_df = aggregate_df.union(df)\n      \n    mean = aggregate_df.select(\n      [F.mean(F.col(column)) for column in scalable_features]\n    ).collect()[0]\n    \n    std = aggregate_df.select(\n      [F.stddev(F.col(column)) for column in scalable_features]\n    ).collect()[0]\n\n    \n    for i in tqdm(range(len(dfs)), desc='Scaling numerical features ...'):\n      # Scaling scalable features\n      for j, feature in enumerate(scalable_features):\n        dfs[i] = dfs[i].withColumn(feature, (dfs[i][feature]-mean[j])/std[j])\n        \ndef impute_missing_values(\n  prices_dfs_new: List[pyspark.sql.DataFrame],\n  key_stats_df: pyspark.sql.DataFrame\n) -> Tuple[List[pyspark.sql.DataFrame], pyspark.sql.DataFrame]:\n  # define the window\n  window = Window.orderBy('Date').rowsBetween(Window.unboundedPreceding, 0)\n\n  # Forward filling values \n  # (ref. https://stackoverflow.com/questions/38131982/forward-fill-missing-values-in-spark-python/50422240#50422240)\n  for i in range(len(prices_dfs_new)):\n    for col_name in prices_dfs_new[i].schema.names:\n      col = F.last(prices_dfs_new[i][col_name], ignorenulls=True).over(window)\n      prices_dfs_new[i] = prices_dfs_new[i].withColumn(col_name, col)\n\n  # In this case this dataframe contains financial reports that may contain NaN values either because that\n  # metric was not available at that time OR because it was monitoring an initial stage of a company growth.\n  # What we do is to apply the classic fast-forward, and fill initial missing values with zeroes.\n  # Please note: we also discard the 'Forward P/E' column since the imputation here would introduce too much noise.\n  key_stats_df_new = key_stats_df.drop('Forward P/E')\n  for col_name in key_stats_df_new.schema.names:\n      col = F.last(key_stats_df_new[col_name], ignorenulls=True).over(window)\n      key_stats_df_new = key_stats_df_new.withColumn(col_name, col)\n  key_stats_df_new = key_stats_df_new.fillna(0.)\n  \n  return prices_dfs_new, key_stats_df_new\n\ndef from_dfs(\n  dfs: List[pyspark.sql.DataFrame],\n  window_size: int = 3,\n  target_col: str = 'Adjusted Close',\n  val_date: str = '2012-01-01',\n  test_date: str = '2013-01-01'\n):\n  # Split the dataset into train/val/test using these dates as boundaries\n  val_begin = pd.Timestamp(val_date)\n  test_begin = pd.Timestamp(test_date)\n  \n  def should_drop(col: pyspark.sql.column, idx: int) -> bool:\n    ''' Returns whether the provided column should be dropped. '''\n    return (col.endswith(f'_{idx}') or 'Ticker' in col or 'Date' in col or 'id' in col)\\\n              and col != f'Adjusted Close_{idx}'\n\n  train_split, val_split, test_split = [], [], []\n  \n  for df in tqdm(dfs, desc='Loading dataset from dfs ...'):\n    # Create an ID for each row based on dates\n    df = df\\\n      .sort('Date')\\\n      .withColumn('id', F.row_number().over(Window.orderBy('Date')))\n    \n    # Split the stock dataset into train/dev/test splits\n    train_df = df.where(F.col('Date') < val_begin)\n    val_df = df.where(F.col('Date').between(val_begin, test_begin-pd.Timedelta(days=1)))\n    test_df = df.where(F.col('Date') >= test_begin)\n    \n    # Add a unique identifier for each column (e.g. Date -> Date_0, Date_1, etc ...)\n    train_df = prepend_columns_index(train_df)\n    val_df = prepend_columns_index(val_df)\n    test_df = prepend_columns_index(test_df)\n    \n    # Convert each split from nxm -> nxm*(w+1), where w is the size of the window\n    train_df = create_window_indexes(train_df, window_size)\n    val_df = create_window_indexes(val_df, window_size)\n    test_df = create_window_indexes(test_df, window_size)\n    \n    # Collect the processed datasets\n    train_split.append(train_df)\n    val_split.append(val_df)\n    test_split.append(test_df)\n  \n  # Initialize the final datasets using the obtained df schema\n  train_ds = spark.createDataFrame([], train_split[0].schema)\n  val_ds = spark.createDataFrame([], val_split[0].schema)\n  test_ds = spark.createDataFrame([], test_split[0].schema)\n  \n  # Collect all the dataframes into a single df for each data split\n  for df in train_split: train_ds = train_ds.union(df)\n  for df in val_split: val_ds = val_ds.union(df)\n  for df in test_split: test_ds = test_ds.union(df)\n  \n  # Drop unused columns for the target variable and rename the target column as 'y'\n  drop_cols = [col for col in test_ds.columns if should_drop(col, window_size)]\n  train_ds = train_ds.drop(*drop_cols).withColumnRenamed(f'Adjusted Close_{window_size}', 'y')\n  val_ds = val_ds.drop(*drop_cols).withColumnRenamed(f'Adjusted Close_{window_size}', 'y')\n  test_ds = test_ds.drop(*drop_cols).withColumnRenamed(f'Adjusted Close_{window_size}', 'y')\n  \n  # Rename columns to make them compatible with Apache Parquet format\n  target_cols = list(map(lambda x: '_'.join(re.split(' |/', x)), train_ds.columns))\n  for c, target in zip(train_ds.columns, target_cols): train_ds = train_ds.withColumnRenamed(c, target)\n  for c, target in zip(val_ds.columns, target_cols): val_ds = val_ds.withColumnRenamed(c, target)\n  for c, target in zip(test_ds.columns, target_cols): test_ds = test_ds.withColumnRenamed(c, target)\n    \n  # Compute the set of unique features in each split\n  features = list(set(c[:-2] for c in train_ds.columns if len(c) >= 2))\n\n  # Convert each split to have, at each timestep (column), the collection of features at that timestep\n  for timestep in range(window_size):\n    # Consider all the features in this timestep\n    current_cols = list(map(lambda c: f'{c}_{timestep}', features))\n    # Convert (price_0, sma_0, market_cap_0) -> 0: (price|sma|market_cap) \n    train_ds = train_ds.withColumn(f'x_{timestep}', F.array(current_cols)).drop(*current_cols)\n    val_ds = val_ds.withColumn(f'x_{timestep}', F.array(current_cols)).drop(*current_cols)\n    test_ds = test_ds.withColumn(f'x_{timestep}', F.array(current_cols)).drop(*current_cols)\n  \n  return train_ds, val_ds, test_ds, features\n\ndef prepend_columns_index(\n  df: pyspark.sql.DataFrame,\n  idx: int = 0\n) -> pyspark.sql.DataFrame:\n  ''' Utility function that returns a new dataframe where columns are preceeded by [idx]. '''\n  for col in df.schema.names:\n    # If this is not the first time this function is applied, simply edit the previous identifier\n    new_col = f'{col}_{idx}' if idx == 0 else f'{col[:-2]}_{idx}'\n    df = df.withColumnRenamed(col, new_col)\n  return df\n\ndef create_window_indexes(df: pyspark.sql.DataFrame, window_size: int) -> pyspark.sql.DataFrame:\n  ''' Apply self join multiple times to the input dataframe, return a new one of size (df.count(), len(df.columns)*window_size) '''\n  joined_df = df\n  for win_idx in range(1, window_size+1):\n    joined_df = joined_df.join(\n      prepend_columns_index(df, win_idx),\n      F.col('id_0') == F.col(f'id_{win_idx}') - win_idx\n    )\n  return joined_df\n\ndef collate_fn(\n  time_steps: List[str],\n  batch: List[Dict[str, np.array]]\n) -> Tuple[torch.Tensor, torch.Tensor]:\n  ''' Returns (x, y) pairs where x is a vector of shape: (window_size, feature_size). '''\n  X = np.asarray([np.stack(itemgetter(*time_steps)(d)) for d in batch])\n  Y = np.asarray([d['y'] for d in batch])\n  return torch.from_numpy(X).double(), torch.from_numpy(Y).double()\n\ndef data_loader_fn(window_size: int, **kwargs) -> DataLoader:\n  ''' Override default behaviour and return a petastorm.Dataset with custom collate function. '''\n  time_steps = [f'x_{time_step}' for time_step in range(window_size)]\n  return DataLoader(**kwargs, collate_fn=partial(collate_fn, time_steps))\n\ndef r2_score(y_hat: np.ndarray, y: np.ndarray) -> float:\n    ''' Computes the R Squared coefficient between y_hat and y. '''\n    rss = torch.sum((y - y_hat) ** 2)\n    tss = torch.sum((y - y.mean()) ** 2)\n    return 1 - rss / tss\n\ndef adjusted_r2_score(y_hat: np.ndarray, y: np.ndarray, p: int) -> float:\n    ''' Computes the Adjusted R Squared coefficient between y_hat and y. '''\n    rss = torch.sum((y - y_hat) ** 2)\n    tss = torch.sum((y - y.mean()) ** 2)\n    df_e = y.shape[0] - p - 1\n    df_t = y.shape[0] - 1\n    return 1 - (rss / tss) * (df_t / df_e)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ebf7570c-7796-4442-9a41-c7a8e9069d60"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Technical indicators"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"707b227e-4c9c-4943-b14a-db5253fec795"}}},{"cell_type":"code","source":["def add_sma(dfs: List[pyspark.sql.DataFrame], period: int = 10) -> None:\n    ''' Computes the Simple Moving Average from a given dataframe. '''\n    w = (Window().partitionBy(\"Adjusted Close\").orderBy(F.col(\"Date\").cast('long')).rangeBetween(-period*86400, 0))\n    #w = Window().partitionBy(\"Adjusted Close\").orderBy(F.col(\"Date\"))\n    for i in tqdm(range(len(dfs)), desc='Adding SMA ...'):\n        dfs[i] = dfs[i].withColumn(\n          \"SMA\",\n          F.avg(\"Adjusted Close\").over(w)\n        )\n\n        \ndef add_rsi(dfs: List[pyspark.sql.DataFrame], period: int = 14) -> None:\n    ''' Computes the Relative Strength Index from a given dataframe. \n        Formula available at https://en.wikipedia.org/wiki/Relative_strength_index.\n        Also adds overbought and oversold when the RSI index hits 70 or 30.'''\n    for j in tqdm(range(len(dfs)), desc='Adding RSI ...'):\n        \n        dateCol = dfs[j][\"Date\"]\n      \n        w = Window.partitionBy().orderBy(\"Date\")\n\n        dfs[j] = dfs[j].withColumn(\"prev_adj_close\", F.lag(dfs[j][\"Adjusted Close\"]).over(w))\n        dfs[j] = dfs[j].withColumn(\"current_gain\", F.when(dfs[j][\"Adjusted Close\"] >= dfs[j][\"prev_adj_close\"],\n                                                          dfs[j][\"Adjusted Close\"] - dfs[j][\"prev_adj_close\"])\n                                                          .otherwise(0.0))\n        dfs[j] = dfs[j].withColumn(\"current_loss\", F.when(dfs[j][\"prev_adj_close\"] >= dfs[j][\"Adjusted Close\"],\n                                                         dfs[j][\"prev_adj_close\"] - dfs[j][\"Adjusted Close\"])\n                                                         .otherwise(0.0))\n          \n        w = (Window().partitionBy(\"current_gain\").orderBy(F.col(\"Date\").cast('long')).rangeBetween(-period*86400, 0))\n        dfs[j] = dfs[j].withColumn(\n          \"smmau\",\n          F.avg(\"current_gain\").over(w)\n        )\n        \n        w = (Window().partitionBy(\"current_loss\").orderBy(F.col(\"Date\").cast('long')).rangeBetween(-period*86400, 0))\n        dfs[j] = dfs[j].withColumn(\n          \"smmad\",\n          F.avg(\"current_loss\").over(w)\n        )\n        \n        dfs[j] = dfs[j].withColumn(\"RSI\", 100 - (100/(1+dfs[j][\"smmau\"]/dfs[j][\"smmad\"])))                        \n        dfs[j] = dfs[j].withColumn(\"Overbought\", F.when(dfs[j][\"RSI\"] >= 70, 1.0).otherwise(0.0))\n        dfs[j] = dfs[j].withColumn(\"Oversold\", F.when(dfs[j][\"RSI\"] <= 30, 1.0).otherwise(0.0))\n        dfs[j] = dfs[j].withColumn(\"Date\", dateCol)\n        \n        dfs[j] = dfs[j].drop(\"prev_adj_close\", \"current_gain\", \"current_loss\", \"smmau\", \"smmad\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de4a5d87-ba54-4970-8ecb-54e9ad305164"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"Overview of the missing values in the key_stats dataframe\\n\")\nkey_stats_summary = missing_values_summary(key_stats_df)\nkey_stats_summary"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9a201af9-db34-4924-81d9-4982833e72e1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Overview of the missing values in the key_stats dataframe\n\nOut[13]: Row(Date=0.0, Ticker=0.0, Price=1.99, DE Ratio=18.607, Trailing P/E=9.652, Price/Sales=0.498, Price/Book=2.189, Profit Margin=1.194, Operating Margin=0.498, Return on Assets=1.99, Return on Equity=2.786, Revenue Per Share=0.398, Market Cap=0.199, Enterprise Value=1.095, Forward P/E=46.269, PEG Ratio=4.776, Enterprise Value/Revenue=1.294, Enterprise Value/EBITDA=7.96, Revenue=1.294, Gross Profit=2.886, EBITDA=7.662, Net Income Avl to Common =0.1, Diluted EPS=0.995, Earnings Growth=17.015, Revenue Growth=1.194, Total Cash=2.189, Total Cash Per Share=1.095, Total Debt=8.159, Current Ratio=6.567, Book Value Per Share=0.199, Cash Flow=11.542, Beta=2.886)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Overview of the missing values in the key_stats dataframe\n\nOut[13]: Row(Date=0.0, Ticker=0.0, Price=1.99, DE Ratio=18.607, Trailing P/E=9.652, Price/Sales=0.498, Price/Book=2.189, Profit Margin=1.194, Operating Margin=0.498, Return on Assets=1.99, Return on Equity=2.786, Revenue Per Share=0.398, Market Cap=0.199, Enterprise Value=1.095, Forward P/E=46.269, PEG Ratio=4.776, Enterprise Value/Revenue=1.294, Enterprise Value/EBITDA=7.96, Revenue=1.294, Gross Profit=2.886, EBITDA=7.662, Net Income Avl to Common =0.1, Diluted EPS=0.995, Earnings Growth=17.015, Revenue Growth=1.194, Total Cash=2.189, Total Cash Per Share=1.095, Total Debt=8.159, Current Ratio=6.567, Book Value Per Share=0.199, Cash Flow=11.542, Beta=2.886)</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Missing values imputation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db3487d2-05a9-43f2-a9d0-1feb1ece31f9"}}},{"cell_type":"code","source":["summary = prices_df_nan_summary(prices_dfs, dfs_names)\npx.bar(summary, x='Stock name', y='Missing data (%)', hover_data=['Count'], title=\"Stock price dataset before preprocessing (only columns with missing values are displayed)\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c77cdd70-d8af-43db-b097-f9ce91f1c266"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\rGenerating prices summary ...:   0%|          | 0/9 [00:00&lt;?, ?it/s]\rGenerating prices summary ...:  11%|█         | 1/9 [00:01&lt;00:10,  1.34s/it]\rGenerating prices summary ...:  22%|██▏       | 2/9 [00:02&lt;00:07,  1.09s/it]\rGenerating prices summary ...:  33%|███▎      | 3/9 [00:03&lt;00:05,  1.01it/s]\rGenerating prices summary ...:  44%|████▍     | 4/9 [00:04&lt;00:06,  1.31s/it]\rGenerating prices summary ...:  56%|█████▌    | 5/9 [00:05&lt;00:04,  1.13s/it]\rGenerating prices summary ...:  67%|██████▋   | 6/9 [00:06&lt;00:03,  1.06s/it]\rGenerating prices summary ...:  78%|███████▊  | 7/9 [00:07&lt;00:01,  1.00it/s]\rGenerating prices summary ...:  89%|████████▉ | 8/9 [00:08&lt;00:01,  1.08s/it]\rGenerating prices summary ...: 100%|██████████| 9/9 [00:09&lt;00:00,  1.05s/it]\rGenerating prices summary ...: 100%|██████████| 9/9 [00:09&lt;00:00,  1.09s/it]\nOut[14]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\rGenerating prices summary ...:   0%|          | 0/9 [00:00&lt;?, ?it/s]\rGenerating prices summary ...:  11%|█         | 1/9 [00:01&lt;00:10,  1.34s/it]\rGenerating prices summary ...:  22%|██▏       | 2/9 [00:02&lt;00:07,  1.09s/it]\rGenerating prices summary ...:  33%|███▎      | 3/9 [00:03&lt;00:05,  1.01it/s]\rGenerating prices summary ...:  44%|████▍     | 4/9 [00:04&lt;00:06,  1.31s/it]\rGenerating prices summary ...:  56%|█████▌    | 5/9 [00:05&lt;00:04,  1.13s/it]\rGenerating prices summary ...:  67%|██████▋   | 6/9 [00:06&lt;00:03,  1.06s/it]\rGenerating prices summary ...:  78%|███████▊  | 7/9 [00:07&lt;00:01,  1.00it/s]\rGenerating prices summary ...:  89%|████████▉ | 8/9 [00:08&lt;00:01,  1.08s/it]\rGenerating prices summary ...: 100%|██████████| 9/9 [00:09&lt;00:00,  1.05s/it]\rGenerating prices summary ...: 100%|██████████| 9/9 [00:09&lt;00:00,  1.09s/it]\nOut[14]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"52dd225a-77a5-4093-bb63-4686d1dd1251\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"52dd225a-77a5-4093-bb63-4686d1dd1251\")) {                    Plotly.newPlot(                        \"52dd225a-77a5-4093-bb63-4686d1dd1251\",                        [{\"alignmentgroup\": \"True\", \"customdata\": [[1]], \"hovertemplate\": \"Stock name=%{x}<br>Missing data (%)=%{y}<br>Count=%{customdata[0]}<extra></extra>\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\"}, \"name\": \"\", \"offsetgroup\": \"\", \"orientation\": \"v\", \"showlegend\": false, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"AAPL\"], \"xaxis\": \"x\", \"y\": [0.01], \"yaxis\": \"y\"}],                        {\"barmode\": \"relative\", \"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Stock price dataset before preprocessing (only columns with missing values are displayed)\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Stock name\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Missing data (%)\"}}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"52dd225a-77a5-4093-bb63-4686d1dd1251\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"52dd225a-77a5-4093-bb63-4686d1dd1251\")) {                    Plotly.newPlot(                        \"52dd225a-77a5-4093-bb63-4686d1dd1251\",                        [{\"alignmentgroup\": \"True\", \"customdata\": [[1]], \"hovertemplate\": \"Stock name=%{x}<br>Missing data (%)=%{y}<br>Count=%{customdata[0]}<extra></extra>\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\"}, \"name\": \"\", \"offsetgroup\": \"\", \"orientation\": \"v\", \"showlegend\": false, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"AAPL\"], \"xaxis\": \"x\", \"y\": [0.01], \"yaxis\": \"y\"}],                        {\"barmode\": \"relative\", \"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Stock price dataset before preprocessing (only columns with missing values are displayed)\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Stock name\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Missing data (%)\"}}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>"]}}],"execution_count":0},{"cell_type":"markdown","source":["For most of the above stocks with missing values, we noticed that they indeed exist up to a given time and after that no more data is available. It may due to a business failure, hence no more stocks will be exchanged from that moment on."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"46156c58-76a8-40c8-88a3-b4bf0a800dd5"}}},{"cell_type":"code","source":["# Clear our input data from training NaN values\nprices_dfs_new = [remove_trailing_nan(df,name) for df,name in tqdm(zip(prices_dfs, dfs_names), total=len(prices_dfs), desc='Removing trailing NaN values ...')]\n\n# Remove INTH stock from our dataset since it contains many inactivity periods\n#inth_idx = dfs_names.index('INTH') #TODO: uncomment\n#del dfs_names[inth_idx] #TODO: uncomment\n#del prices_dfs_new[inth_idx] #TODO: uncomment\n\nsummary = prices_df_nan_summary(prices_dfs_new, dfs_names)\npx.bar(summary, x='Stock name', y='Missing data (%)', hover_data=['Count'], title=\"Stock price dataset after preprocessing (only columns with missing values are displayed)\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5884e89a-4386-4042-bd50-39dd70e3cef8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\rRemoving trailing NaN values ...:   0%|          | 0/9 [00:00&lt;?, ?it/s]\rRemoving trailing NaN values ...:  11%|█         | 1/9 [00:03&lt;00:28,  3.62s/it]\rRemoving trailing NaN values ...:  22%|██▏       | 2/9 [00:05&lt;00:19,  2.75s/it]\rRemoving trailing NaN values ...:  33%|███▎      | 3/9 [00:07&lt;00:14,  2.37s/it]\rRemoving trailing NaN values ...:  44%|████▍     | 4/9 [00:10&lt;00:12,  2.60s/it]\rRemoving trailing NaN values ...:  56%|█████▌    | 5/9 [00:12&lt;00:09,  2.49s/it]\rRemoving trailing NaN values ...:  67%|██████▋   | 6/9 [00:15&lt;00:07,  2.44s/it]\rRemoving trailing NaN values ...:  78%|███████▊  | 7/9 [00:17&lt;00:04,  2.29s/it]\rRemoving trailing NaN values ...:  89%|████████▉ | 8/9 [00:19&lt;00:02,  2.18s/it]\rRemoving trailing NaN values ...: 100%|██████████| 9/9 [00:20&lt;00:00,  2.02s/it]\rRemoving trailing NaN values ...: 100%|██████████| 9/9 [00:20&lt;00:00,  2.32s/it]\n\rGenerating prices summary ...:   0%|          | 0/9 [00:00&lt;?, ?it/s]\rGenerating prices summary ...:  11%|█         | 1/9 [00:01&lt;00:12,  1.59s/it]\rGenerating prices summary ...:  22%|██▏       | 2/9 [00:02&lt;00:10,  1.48s/it]\rGenerating prices summary ...:  33%|███▎      | 3/9 [00:04&lt;00:09,  1.52s/it]\rGenerating prices summary ...:  44%|████▍     | 4/9 [00:08&lt;00:11,  2.34s/it]\rGenerating prices summary ...:  56%|█████▌    | 5/9 [00:09&lt;00:08,  2.11s/it]\rGenerating prices summary ...:  67%|██████▋   | 6/9 [00:11&lt;00:05,  1.92s/it]\rGenerating prices summary ...:  78%|███████▊  | 7/9 [00:12&lt;00:03,  1.71s/it]\rGenerating prices summary ...:  89%|████████▉ | 8/9 [00:14&lt;00:01,  1.64s/it]\rGenerating prices summary ...: 100%|██████████| 9/9 [00:15&lt;00:00,  1.49s/it]\rGenerating prices summary ...: 100%|██████████| 9/9 [00:15&lt;00:00,  1.70s/it]\nOut[15]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\rRemoving trailing NaN values ...:   0%|          | 0/9 [00:00&lt;?, ?it/s]\rRemoving trailing NaN values ...:  11%|█         | 1/9 [00:03&lt;00:28,  3.62s/it]\rRemoving trailing NaN values ...:  22%|██▏       | 2/9 [00:05&lt;00:19,  2.75s/it]\rRemoving trailing NaN values ...:  33%|███▎      | 3/9 [00:07&lt;00:14,  2.37s/it]\rRemoving trailing NaN values ...:  44%|████▍     | 4/9 [00:10&lt;00:12,  2.60s/it]\rRemoving trailing NaN values ...:  56%|█████▌    | 5/9 [00:12&lt;00:09,  2.49s/it]\rRemoving trailing NaN values ...:  67%|██████▋   | 6/9 [00:15&lt;00:07,  2.44s/it]\rRemoving trailing NaN values ...:  78%|███████▊  | 7/9 [00:17&lt;00:04,  2.29s/it]\rRemoving trailing NaN values ...:  89%|████████▉ | 8/9 [00:19&lt;00:02,  2.18s/it]\rRemoving trailing NaN values ...: 100%|██████████| 9/9 [00:20&lt;00:00,  2.02s/it]\rRemoving trailing NaN values ...: 100%|██████████| 9/9 [00:20&lt;00:00,  2.32s/it]\n\rGenerating prices summary ...:   0%|          | 0/9 [00:00&lt;?, ?it/s]\rGenerating prices summary ...:  11%|█         | 1/9 [00:01&lt;00:12,  1.59s/it]\rGenerating prices summary ...:  22%|██▏       | 2/9 [00:02&lt;00:10,  1.48s/it]\rGenerating prices summary ...:  33%|███▎      | 3/9 [00:04&lt;00:09,  1.52s/it]\rGenerating prices summary ...:  44%|████▍     | 4/9 [00:08&lt;00:11,  2.34s/it]\rGenerating prices summary ...:  56%|█████▌    | 5/9 [00:09&lt;00:08,  2.11s/it]\rGenerating prices summary ...:  67%|██████▋   | 6/9 [00:11&lt;00:05,  1.92s/it]\rGenerating prices summary ...:  78%|███████▊  | 7/9 [00:12&lt;00:03,  1.71s/it]\rGenerating prices summary ...:  89%|████████▉ | 8/9 [00:14&lt;00:01,  1.64s/it]\rGenerating prices summary ...: 100%|██████████| 9/9 [00:15&lt;00:00,  1.49s/it]\rGenerating prices summary ...: 100%|██████████| 9/9 [00:15&lt;00:00,  1.70s/it]\nOut[15]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"b6acbd64-44f3-4243-a636-b8b205b8b9fe\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b6acbd64-44f3-4243-a636-b8b205b8b9fe\")) {                    Plotly.newPlot(                        \"b6acbd64-44f3-4243-a636-b8b205b8b9fe\",                        [{\"alignmentgroup\": \"True\", \"customdata\": [[1]], \"hovertemplate\": \"Stock name=%{x}<br>Missing data (%)=%{y}<br>Count=%{customdata[0]}<extra></extra>\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\"}, \"name\": \"\", \"offsetgroup\": \"\", \"orientation\": \"v\", \"showlegend\": false, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"AAPL\"], \"xaxis\": \"x\", \"y\": [0.01], \"yaxis\": \"y\"}],                        {\"barmode\": \"relative\", \"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Stock price dataset after preprocessing (only columns with missing values are displayed)\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Stock name\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Missing data (%)\"}}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"b6acbd64-44f3-4243-a636-b8b205b8b9fe\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b6acbd64-44f3-4243-a636-b8b205b8b9fe\")) {                    Plotly.newPlot(                        \"b6acbd64-44f3-4243-a636-b8b205b8b9fe\",                        [{\"alignmentgroup\": \"True\", \"customdata\": [[1]], \"hovertemplate\": \"Stock name=%{x}<br>Missing data (%)=%{y}<br>Count=%{customdata[0]}<extra></extra>\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\"}, \"name\": \"\", \"offsetgroup\": \"\", \"orientation\": \"v\", \"showlegend\": false, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"AAPL\"], \"xaxis\": \"x\", \"y\": [0.01], \"yaxis\": \"y\"}],                        {\"barmode\": \"relative\", \"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Stock price dataset after preprocessing (only columns with missing values are displayed)\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Stock name\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Missing data (%)\"}}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>"]}}],"execution_count":0},{"cell_type":"markdown","source":["At this point we use the fast forward imputation technique to fill-in missing values. Please note that in this case missing values are mostly due to holidays or periods when stocks are not exchanged."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b219a552-fd13-453f-826c-71fb94bfd81f"}}},{"cell_type":"markdown","source":["## Hyperparameters"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c47e3765-14b1-4228-a3b8-51985f53cd14"}}},{"cell_type":"code","source":["@dataclasses.dataclass\nclass HParams:\n  input_dim: int = -1  # Denoted by data transformations\n  window_size: int = 5\n  batch_size: int = 1024\n  features: int = -1  # Denoted by data transformations\n  hidden_dim: int = 128\n  num_layers: int = 1\n  dropout: int = 0.5\n  lr: int = 0.1\n    \nhparams = HParams()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0fb8282-de11-4c4a-86ba-39b556d9b988"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Building our new dataset"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3595c39e-c759-41d4-a927-ab75e577b16e"}}},{"cell_type":"code","source":["# Impute missing values in the prices dataset (i.e. fast-forward last valid values)\nprices_dfs_new, key_stats_df_new = impute_missing_values(prices_dfs_new, key_stats_df)\n\n# Merge the stock price dataset with fundamental data of the relative company\naggregate_dfs = merge_prices_fundamentals(prices_dfs_new, key_stats_df_new, dfs_names)\n\n# Fill gaps from the original dataset\ndfs = fill_missing_days(aggregate_dfs)\n                  \n# Add SMA indicator to each dataframe\nadd_sma(dfs)\n\n# Add RSI indicator to each dataframe\nadd_rsi(dfs)\n\n# Scale numerical features\nscale_features(dfs)\n\n# Create train/dev/test splits\ntrain_ds, val_ds, test_ds, features = from_dfs(dfs, window_size=hparams.window_size)\nhparams.input_dim = len(features)\nhparams.features = features"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b215510b-4ef8-4b04-b097-c467153c4c84"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\rMerging the datasets ...:   0%|          | 0/56 [00:00&lt;?, ?it/s]\rMerging the datasets ...:  18%|█▊        | 10/56 [00:00&lt;00:01, 31.18it/s]\rMerging the datasets ...:  32%|███▏      | 18/56 [00:00&lt;00:01, 36.88it/s]\rMerging the datasets ...:  39%|███▉      | 22/56 [00:00&lt;00:01, 32.05it/s]\rMerging the datasets ...:  54%|█████▎    | 30/56 [00:00&lt;00:00, 38.72it/s]\rMerging the datasets ...:  79%|███████▊  | 44/56 [00:00&lt;00:00, 57.03it/s]\rMerging the datasets ...: 100%|██████████| 56/56 [00:01&lt;00:00, 62.58it/s]\rMerging the datasets ...: 100%|██████████| 56/56 [00:01&lt;00:00, 49.74it/s]\n\rFilling missing days ...:   0%|          | 0/6 [00:00&lt;?, ?it/s]\rFilling missing days ...:  17%|█▋        | 1/6 [00:05&lt;00:27,  5.57s/it]\rFilling missing days ...:  33%|███▎      | 2/6 [00:08&lt;00:17,  4.31s/it]\rFilling missing days ...:  50%|█████     | 3/6 [00:13&lt;00:12,  4.22s/it]\rFilling missing days ...:  67%|██████▋   | 4/6 [00:16&lt;00:07,  3.96s/it]\rFilling missing days ...:  83%|████████▎ | 5/6 [00:19&lt;00:03,  3.56s/it]\rFilling missing days ...: 100%|██████████| 6/6 [00:21&lt;00:00,  3.11s/it]\rFilling missing days ...: 100%|██████████| 6/6 [00:21&lt;00:00,  3.63s/it]\n\rAdding SMA ...:   0%|          | 0/6 [00:00&lt;?, ?it/s]\rAdding SMA ...:  33%|███▎      | 2/6 [00:00&lt;00:00, 12.01it/s]\rAdding SMA ...:  83%|████████▎ | 5/6 [00:00&lt;00:00, 17.66it/s]\rAdding SMA ...: 100%|██████████| 6/6 [00:00&lt;00:00, 17.92it/s]\n\rLoading dataset from dfs ...:   0%|          | 0/6 [00:00&lt;?, ?it/s]\rLoading dataset from dfs ...:  17%|█▋        | 1/6 [00:08&lt;00:41,  8.38s/it]\rLoading dataset from dfs ...:  33%|███▎      | 2/6 [00:14&lt;00:29,  7.32s/it]\rLoading dataset from dfs ...:  50%|█████     | 3/6 [00:21&lt;00:21,  7.03s/it]\rLoading dataset from dfs ...:  67%|██████▋   | 4/6 [00:28&lt;00:13,  6.84s/it]\rLoading dataset from dfs ...:  83%|████████▎ | 5/6 [00:35&lt;00:06,  6.84s/it]\rLoading dataset from dfs ...: 100%|██████████| 6/6 [00:41&lt;00:00,  6.64s/it]\rLoading dataset from dfs ...: 100%|██████████| 6/6 [00:41&lt;00:00,  6.88s/it]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\rMerging the datasets ...:   0%|          | 0/56 [00:00&lt;?, ?it/s]\rMerging the datasets ...:  18%|█▊        | 10/56 [00:00&lt;00:01, 31.18it/s]\rMerging the datasets ...:  32%|███▏      | 18/56 [00:00&lt;00:01, 36.88it/s]\rMerging the datasets ...:  39%|███▉      | 22/56 [00:00&lt;00:01, 32.05it/s]\rMerging the datasets ...:  54%|█████▎    | 30/56 [00:00&lt;00:00, 38.72it/s]\rMerging the datasets ...:  79%|███████▊  | 44/56 [00:00&lt;00:00, 57.03it/s]\rMerging the datasets ...: 100%|██████████| 56/56 [00:01&lt;00:00, 62.58it/s]\rMerging the datasets ...: 100%|██████████| 56/56 [00:01&lt;00:00, 49.74it/s]\n\rFilling missing days ...:   0%|          | 0/6 [00:00&lt;?, ?it/s]\rFilling missing days ...:  17%|█▋        | 1/6 [00:05&lt;00:27,  5.57s/it]\rFilling missing days ...:  33%|███▎      | 2/6 [00:08&lt;00:17,  4.31s/it]\rFilling missing days ...:  50%|█████     | 3/6 [00:13&lt;00:12,  4.22s/it]\rFilling missing days ...:  67%|██████▋   | 4/6 [00:16&lt;00:07,  3.96s/it]\rFilling missing days ...:  83%|████████▎ | 5/6 [00:19&lt;00:03,  3.56s/it]\rFilling missing days ...: 100%|██████████| 6/6 [00:21&lt;00:00,  3.11s/it]\rFilling missing days ...: 100%|██████████| 6/6 [00:21&lt;00:00,  3.63s/it]\n\rAdding SMA ...:   0%|          | 0/6 [00:00&lt;?, ?it/s]\rAdding SMA ...:  33%|███▎      | 2/6 [00:00&lt;00:00, 12.01it/s]\rAdding SMA ...:  83%|████████▎ | 5/6 [00:00&lt;00:00, 17.66it/s]\rAdding SMA ...: 100%|██████████| 6/6 [00:00&lt;00:00, 17.92it/s]\n\rLoading dataset from dfs ...:   0%|          | 0/6 [00:00&lt;?, ?it/s]\rLoading dataset from dfs ...:  17%|█▋        | 1/6 [00:08&lt;00:41,  8.38s/it]\rLoading dataset from dfs ...:  33%|███▎      | 2/6 [00:14&lt;00:29,  7.32s/it]\rLoading dataset from dfs ...:  50%|█████     | 3/6 [00:21&lt;00:21,  7.03s/it]\rLoading dataset from dfs ...:  67%|██████▋   | 4/6 [00:28&lt;00:13,  6.84s/it]\rLoading dataset from dfs ...:  83%|████████▎ | 5/6 [00:35&lt;00:06,  6.84s/it]\rLoading dataset from dfs ...: 100%|██████████| 6/6 [00:41&lt;00:00,  6.64s/it]\rLoading dataset from dfs ...: 100%|██████████| 6/6 [00:41&lt;00:00,  6.88s/it]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##Models definition"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b15deec7-b5a2-49db-a08d-94bd3145ed1c"}}},{"cell_type":"code","source":["class SimpleLSTM(nn.Module):\n  def __init__(self, hparams):\n      super().__init__()\n      self.hparams = hparams\n      self.lstm = nn.LSTM(hparams.input_dim, hparams.hidden_dim, num_layers=hparams.num_layers, batch_first=True)\n      self.fc1 = nn.Linear(hparams.hidden_dim, hparams.hidden_dim//2)\n      self.fc2 = nn.Linear(hparams.hidden_dim//2, 1)\n      self.dropout = nn.Dropout(hparams.dropout)\n\n  def forward(self, x: np.ndarray):\n      x, (h,c) = self.lstm(x)\n      h = self.dropout(h)\n      h = h.view(self.hparams.num_layers, -1, self.hparams.hidden_dim)[-1]\n      x = torch.relu(self.fc1(h))\n      x = self.fc2(x)\n      return x.squeeze()\n\nclass StockPriceRegressor(pl.LightningModule):\n  def __init__(self, hparams: HParams):\n      super().__init__()\n      self.save_hyperparameters(dataclasses.asdict(hparams))\n      self.loss_fn = nn.MSELoss()\n      self.model = SimpleLSTM(self.hparams)\n\n  def training_step(self, batch: Tuple[np.ndarray, np.ndarray], batch_idx: int):\n      x, y = batch\n      y_hat = self.model(x)\n      loss = self.loss_fn(y_hat, y)\n      return loss\n\n  @torch.no_grad()\n  def evaluation(self, batch: Tuple[np.ndarray, np.ndarray]) -> float:\n      x, y = batch\n      y_hat = self.model(x)\n      loss = self.loss_fn(y_hat, y)\n      r2 = r2_score(y_hat, y)\n      # p := no. of explanatory variables in the model (i.e window_size * feature_size)\n      r2_adj = adjusted_r2_score(y_hat, y, x.shape[1] * x.shape[2])\n      return loss, r2, r2_adj\n\n  def validation_step(self, batch: Tuple[np.ndarray, np.ndarray], batch_idx: int) -> None:\n      loss, r2, r2_adj = self.evaluation(batch)\n      metrics = {'val_loss': loss, 'val_r2': r2, 'val_r2_adj': r2_adj}\n      self.log_dict(metrics)\n\n  def test_step(self, batch: Tuple[np.ndarray, np.ndarray], batch_idx: int) -> None:\n      loss, r2, r2_adj = self.evaluation(batch)\n      metrics = {'test_loss': loss, 'test_r2': r2, 'val_r2_adj': r2_adj}\n      self.log_dict(metrics)\n\n  def configure_optimizers(self):\n      return torch.optim.SGD(self.parameters(), lr=self.hparams.lr)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"92ce704a-ec3c-43f9-b503-6fc7bf2aaa65"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Define the number of epochs to run the model on\nhparams.epochs = 5\n\n# Configure the current run\nrun = wandb.init(reinit=True, project='distributed_spf')\nmodel = StockPriceRegressor(hparams).double()\ntrainer = pl.Trainer(\n  logger = WandbLogger(),\n  #accelerator='ddp',\n  log_every_n_steps = 1,\n  max_epochs = hparams.epochs,\n  deterministic = True\n)\n\n# Materialize spark dataframes to DBFS in parqet format\nconverter_train = make_spark_converter(train_ds)\nconverter_valid = make_spark_converter(val_ds)\n\n# Fit the model on training data, and evaluate it on validation split\nwith converter_train.make_torch_dataloader(\n  batch_size=hparams.batch_size, data_loader_fn=partial(data_loader_fn, hparams.window_size), num_epochs=hparams.epochs\n) as train_dataloader, converter_valid.make_torch_dataloader(\n  batch_size=hparams.batch_size, data_loader_fn=partial(data_loader_fn, hparams.window_size), num_epochs=hparams.epochs\n) as valid_dataloader:\n  \n  trainer.fit(model, train_dataloader, valid_dataloader)\n\n# Log the experiments\nrun.finish()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08c49aca-c864-49b2-9a5a-787531af03bd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;IPython.core.display.HTML object&gt;\n&lt;IPython.core.display.HTML object&gt;\n&lt;IPython.core.display.HTML object&gt;\n&lt;IPython.core.display.HTML object&gt;\n&lt;IPython.core.display.HTML object&gt;\n&lt;IPython.core.display.HTML object&gt;\n&lt;IPython.core.display.HTML object&gt;\n&lt;IPython.core.display.HTML object&gt;\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nThe median size 689922 B (&lt; 50 MB) of the parquet files is too small. Total size: 3280858 B. Increase the median file size by calling df.repartition(n) or df.coalesce(n), which might help improve the performance. Parquet files: file:/dbfs/tmp/petastorm/cache/20210514200755-appid-local-1621021446187-88f09c03-c27e-4c96-87f7-3efb965363aa/part-00000-tid-7215225489191546835-6d23c333-065b-4796-ab55-3ab9ec160abc-426-1-c000.parquet, ...\nThe median size 70347 B (&lt; 50 MB) of the parquet files is too small. Total size: 347810 B. Increase the median file size by calling df.repartition(n) or df.coalesce(n), which might help improve the performance. Parquet files: file:/dbfs/tmp/petastorm/cache/20210514205237-appid-local-1621021446187-0803381f-d2d4-4efe-9a34-e5ddb0f5d9bd/part-00000-tid-6687446883553154058-6878712f-694b-4b7a-b4e6-1a10ed274d3f-940-1-c000.parquet, ...\n\n  | Name    | Type       | Params\n---------------------------------------\n0 | loss_fn | MSELoss    | 0     \n1 | model   | SimpleLSTM | 91.3 K\n---------------------------------------\n91.3 K    Trainable params\n0         Non-trainable params\n91.3 K    Total params\n0.365     Total estimated model params size (MB)\n\rValidation sanity check: 0it [00:00, ?it/s]\rValidation sanity check:   0%|          | 0/2 [00:00&lt;?, ?it/s]\rValidation sanity check:  50%|█████     | 1/2 [00:00&lt;00:00,  4.76it/s]\rValidation sanity check: 100%|██████████| 2/2 [00:00&lt;00:00,  4.66it/s]\r                                                                      \rGlobal seed set to 42\n\rTraining: 0it [00:00, ?it/s]\rTraining: 0it [00:00, ?it/s]\rEpoch 0: : 0it [00:00, ?it/s]\rEpoch 0: : 1it [00:00,  2.70it/s]\rEpoch 0: : 1it [00:00,  2.61it/s, loss=242, v_num=jvem]\rEpoch 0: : 2it [00:00,  2.84it/s, loss=242, v_num=jvem]\rEpoch 0: : 2it [00:00,  2.81it/s, loss=161, v_num=jvem]\rEpoch 0: : 3it [00:00,  3.01it/s, loss=161, v_num=jvem]\rEpoch 0: : 3it [00:01,  2.99it/s, loss=4.98e+03, v_num=jvem]\rEpoch 0: : 4it [00:01,  3.20it/s, loss=4.98e+03, v_num=jvem]\rEpoch 0: : 4it [00:01,  3.07it/s, loss=4.07e+03, v_num=jvem]\rEpoch 0: : 5it [00:01,  3.15it/s, loss=4.07e+03, v_num=jvem]\rEpoch 0: : 5it [00:01,  3.14it/s, loss=1.05e+07, v_num=jvem]\rEpoch 0: : 6it [00:01,  3.26it/s, loss=1.05e+07, v_num=jvem]\rEpoch 0: : 6it [00:01,  3.25it/s, loss=7.23e+17, v_num=jvem]\rEpoch 0: : 7it [00:02,  3.34it/s, loss=7.23e+17, v_num=jvem]\rEpoch 0: : 7it [00:02,  3.33it/s, loss=3.76e+33, v_num=jvem]\rEpoch 0: : 8it [00:02,  3.31it/s, loss=3.76e+33, v_num=jvem]\rEpoch 0: : 8it [00:02,  3.30it/s, loss=inf, v_num=jvem]     \rEpoch 0: : 9it [00:02,  3.34it/s, loss=inf, v_num=jvem]\rEpoch 0: : 9it [00:02,  3.33it/s, loss=inf, v_num=jvem]\rEpoch 0: : 10it [00:02,  3.34it/s, loss=inf, v_num=jvem]\rEpoch 0: : 10it [00:03,  3.33it/s, loss=inf, v_num=jvem]\rEpoch 0: : 11it [00:03,  3.37it/s, loss=inf, v_num=jvem]\rEpoch 0: : 11it [00:03,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 12it [00:03,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 12it [00:03,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 13it [00:03,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 13it [00:03,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 14it [00:04,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 14it [00:04,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 15it [00:04,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 15it [00:04,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 16it [00:04,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 16it [00:04,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 17it [00:05,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 17it [00:05,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 18it [00:05,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 18it [00:05,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 19it [00:05,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 19it [00:05,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 20it [00:05,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 20it [00:05,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 21it [00:06,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 21it [00:06,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 22it [00:06,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 22it [00:06,  3.34it/s, loss=nan, v_num=jvem]\rEpoch 0: : 23it [00:06,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 23it [00:06,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 24it [00:07,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 24it [00:07,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 25it [00:07,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 25it [00:07,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 26it [00:07,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 26it [00:07,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 27it [00:08,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 27it [00:08,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 28it [00:08,  3.34it/s, loss=nan, v_num=jvem]\rEpoch 0: : 28it [00:08,  3.34it/s, loss=nan, v_num=jvem]\rEpoch 0: : 29it [00:08,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 29it [00:08,  3.34it/s, loss=nan, v_num=jvem]\rEpoch 0: : 30it [00:08,  3.34it/s, loss=nan, v_num=jvem]\rEpoch 0: : 30it [00:08,  3.34it/s, loss=nan, v_num=jvem]\rEpoch 0: : 31it [00:09,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 31it [00:09,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 32it [00:09,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 32it [00:09,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 33it [00:09,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 33it [00:09,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 34it [00:10,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 34it [00:10,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 35it [00:10,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 35it [00:10,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 36it [00:10,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 36it [00:10,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 37it [00:10,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 37it [00:10,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 38it [00:11,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 38it [00:11,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 39it [00:11,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 39it [00:11,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 40it [00:11,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 40it [00:11,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 41it [00:12,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 41it [00:12,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 42it [00:12,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 42it [00:12,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 43it [00:12,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 43it [00:12,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 44it [00:12,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 44it [00:12,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 45it [00:13,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 45it [00:13,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 46it [00:13,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 46it [00:13,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 47it [00:13,  3.40it/s, loss=nan, v_num=jvem]\rEpoch 0: : 47it [00:13,  3.40it/s, loss=nan, v_num=jvem]\rEpoch 0: : 48it [00:14,  3.40it/s, loss=nan, v_num=jvem]\rEpoch 0: : 48it [00:14,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 49it [00:14,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 49it [00:14,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 50it [00:14,  3.41it/s, loss=nan, v_num=jvem]\rEpoch 0: : 50it [00:14,  3.41it/s, loss=nan, v_num=jvem]\rEpoch 0: : 51it [00:14,  3.45it/s, loss=nan, v_num=jvem]\rEpoch 0: : 51it [00:14,  3.45it/s, loss=nan, v_num=jvem]\n\rValidating: 0it [00:00, ?it/s]\n\rValidating: 0it [00:00, ?it/s]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;IPython.core.display.HTML object&gt;\n&lt;IPython.core.display.HTML object&gt;\n&lt;IPython.core.display.HTML object&gt;\n&lt;IPython.core.display.HTML object&gt;\n&lt;IPython.core.display.HTML object&gt;\n&lt;IPython.core.display.HTML object&gt;\n&lt;IPython.core.display.HTML object&gt;\n&lt;IPython.core.display.HTML object&gt;\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nThe median size 689922 B (&lt; 50 MB) of the parquet files is too small. Total size: 3280858 B. Increase the median file size by calling df.repartition(n) or df.coalesce(n), which might help improve the performance. Parquet files: file:/dbfs/tmp/petastorm/cache/20210514200755-appid-local-1621021446187-88f09c03-c27e-4c96-87f7-3efb965363aa/part-00000-tid-7215225489191546835-6d23c333-065b-4796-ab55-3ab9ec160abc-426-1-c000.parquet, ...\nThe median size 70347 B (&lt; 50 MB) of the parquet files is too small. Total size: 347810 B. Increase the median file size by calling df.repartition(n) or df.coalesce(n), which might help improve the performance. Parquet files: file:/dbfs/tmp/petastorm/cache/20210514205237-appid-local-1621021446187-0803381f-d2d4-4efe-9a34-e5ddb0f5d9bd/part-00000-tid-6687446883553154058-6878712f-694b-4b7a-b4e6-1a10ed274d3f-940-1-c000.parquet, ...\n\n Name    | Type       | Params\n---------------------------------------\n0 | loss_fn | MSELoss    | 0     \n1 | model   | SimpleLSTM | 91.3 K\n---------------------------------------\n91.3 K    Trainable params\n0         Non-trainable params\n91.3 K    Total params\n0.365     Total estimated model params size (MB)\n\rValidation sanity check: 0it [00:00, ?it/s]\rValidation sanity check:   0%|          | 0/2 [00:00&lt;?, ?it/s]\rValidation sanity check:  50%|█████     | 1/2 [00:00&lt;00:00,  4.76it/s]\rValidation sanity check: 100%|██████████| 2/2 [00:00&lt;00:00,  4.66it/s]\r                                                                      \rGlobal seed set to 42\n\rTraining: 0it [00:00, ?it/s]\rTraining: 0it [00:00, ?it/s]\rEpoch 0: : 0it [00:00, ?it/s]\rEpoch 0: : 1it [00:00,  2.70it/s]\rEpoch 0: : 1it [00:00,  2.61it/s, loss=242, v_num=jvem]\rEpoch 0: : 2it [00:00,  2.84it/s, loss=242, v_num=jvem]\rEpoch 0: : 2it [00:00,  2.81it/s, loss=161, v_num=jvem]\rEpoch 0: : 3it [00:00,  3.01it/s, loss=161, v_num=jvem]\rEpoch 0: : 3it [00:01,  2.99it/s, loss=4.98e+03, v_num=jvem]\rEpoch 0: : 4it [00:01,  3.20it/s, loss=4.98e+03, v_num=jvem]\rEpoch 0: : 4it [00:01,  3.07it/s, loss=4.07e+03, v_num=jvem]\rEpoch 0: : 5it [00:01,  3.15it/s, loss=4.07e+03, v_num=jvem]\rEpoch 0: : 5it [00:01,  3.14it/s, loss=1.05e+07, v_num=jvem]\rEpoch 0: : 6it [00:01,  3.26it/s, loss=1.05e+07, v_num=jvem]\rEpoch 0: : 6it [00:01,  3.25it/s, loss=7.23e+17, v_num=jvem]\rEpoch 0: : 7it [00:02,  3.34it/s, loss=7.23e+17, v_num=jvem]\rEpoch 0: : 7it [00:02,  3.33it/s, loss=3.76e+33, v_num=jvem]\rEpoch 0: : 8it [00:02,  3.31it/s, loss=3.76e+33, v_num=jvem]\rEpoch 0: : 8it [00:02,  3.30it/s, loss=inf, v_num=jvem]     \rEpoch 0: : 9it [00:02,  3.34it/s, loss=inf, v_num=jvem]\rEpoch 0: : 9it [00:02,  3.33it/s, loss=inf, v_num=jvem]\rEpoch 0: : 10it [00:02,  3.34it/s, loss=inf, v_num=jvem]\rEpoch 0: : 10it [00:03,  3.33it/s, loss=inf, v_num=jvem]\rEpoch 0: : 11it [00:03,  3.37it/s, loss=inf, v_num=jvem]\rEpoch 0: : 11it [00:03,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 12it [00:03,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 12it [00:03,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 13it [00:03,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 13it [00:03,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 14it [00:04,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 14it [00:04,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 15it [00:04,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 15it [00:04,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 16it [00:04,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 16it [00:04,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 17it [00:05,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 17it [00:05,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 18it [00:05,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 18it [00:05,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 19it [00:05,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 19it [00:05,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 20it [00:05,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 20it [00:05,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 21it [00:06,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 21it [00:06,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 22it [00:06,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 22it [00:06,  3.34it/s, loss=nan, v_num=jvem]\rEpoch 0: : 23it [00:06,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 23it [00:06,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 24it [00:07,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 24it [00:07,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 25it [00:07,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 25it [00:07,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 26it [00:07,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 26it [00:07,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 27it [00:08,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 27it [00:08,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 28it [00:08,  3.34it/s, loss=nan, v_num=jvem]\rEpoch 0: : 28it [00:08,  3.34it/s, loss=nan, v_num=jvem]\rEpoch 0: : 29it [00:08,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 29it [00:08,  3.34it/s, loss=nan, v_num=jvem]\rEpoch 0: : 30it [00:08,  3.34it/s, loss=nan, v_num=jvem]\rEpoch 0: : 30it [00:08,  3.34it/s, loss=nan, v_num=jvem]\rEpoch 0: : 31it [00:09,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 31it [00:09,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 32it [00:09,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 32it [00:09,  3.35it/s, loss=nan, v_num=jvem]\rEpoch 0: : 33it [00:09,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 33it [00:09,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 34it [00:10,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 34it [00:10,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 35it [00:10,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 35it [00:10,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 36it [00:10,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 36it [00:10,  3.36it/s, loss=nan, v_num=jvem]\rEpoch 0: : 37it [00:10,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 37it [00:10,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 38it [00:11,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 38it [00:11,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 39it [00:11,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 39it [00:11,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 40it [00:11,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 40it [00:11,  3.37it/s, loss=nan, v_num=jvem]\rEpoch 0: : 41it [00:12,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 41it [00:12,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 42it [00:12,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 42it [00:12,  3.38it/s, loss=nan, v_num=jvem]\rEpoch 0: : 43it [00:12,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 43it [00:12,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 44it [00:12,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 44it [00:12,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 45it [00:13,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 45it [00:13,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 46it [00:13,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 46it [00:13,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 47it [00:13,  3.40it/s, loss=nan, v_num=jvem]\rEpoch 0: : 47it [00:13,  3.40it/s, loss=nan, v_num=jvem]\rEpoch 0: : 48it [00:14,  3.40it/s, loss=nan, v_num=jvem]\rEpoch 0: : 48it [00:14,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 49it [00:14,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 49it [00:14,  3.39it/s, loss=nan, v_num=jvem]\rEpoch 0: : 50it [00:14,  3.41it/s, loss=nan, v_num=jvem]\rEpoch 0: : 50it [00:14,  3.41it/s, loss=nan, v_num=jvem]\rEpoch 0: : 51it [00:14,  3.45it/s, loss=nan, v_num=jvem]\rEpoch 0: : 51it [00:14,  3.45it/s, loss=nan, v_num=jvem]\n\rValidating: 0it [00:00, ?it/s]\n\rValidating: 0it [00:00, ?it/s]</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NotImplementedError</span>                       Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3754394103994545&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     20</span> ) as valid_dataloader:\n<span class=\"ansi-green-intense-fg ansi-bold\">     21</span> \n<span class=\"ansi-green-fg\">---&gt; 22</span><span class=\"ansi-red-fg\">   </span>trainer<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>model<span class=\"ansi-blue-fg\">,</span> train_dataloader<span class=\"ansi-blue-fg\">,</span> valid_dataloader<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     23</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     24</span> run<span class=\"ansi-blue-fg\">.</span>finish<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py</span> in <span class=\"ansi-cyan-fg\">fit</span><span class=\"ansi-blue-fg\">(self, model, train_dataloader, val_dataloaders, datamodule)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    456</span>         )\n<span class=\"ansi-green-intense-fg ansi-bold\">    457</span> \n<span class=\"ansi-green-fg\">--&gt; 458</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_run<span class=\"ansi-blue-fg\">(</span>model<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    459</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    460</span>         <span class=\"ansi-green-fg\">assert</span> self<span class=\"ansi-blue-fg\">.</span>state<span class=\"ansi-blue-fg\">.</span>stopped\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py</span> in <span class=\"ansi-cyan-fg\">_run</span><span class=\"ansi-blue-fg\">(self, model)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    754</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    755</span>         <span class=\"ansi-red-fg\"># dispatch `start_training` or `start_evaluating` or `start_predicting`</span>\n<span class=\"ansi-green-fg\">--&gt; 756</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>dispatch<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    757</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    758</span>         <span class=\"ansi-red-fg\"># plugin will finalized fitting (e.g. ddp_spawn will load trained model)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py</span> in <span class=\"ansi-cyan-fg\">dispatch</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    795</span>             self<span class=\"ansi-blue-fg\">.</span>accelerator<span class=\"ansi-blue-fg\">.</span>start_predicting<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    796</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 797</span><span class=\"ansi-red-fg\">             </span>self<span class=\"ansi-blue-fg\">.</span>accelerator<span class=\"ansi-blue-fg\">.</span>start_training<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    798</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    799</span>     <span class=\"ansi-green-fg\">def</span> run_stage<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py</span> in <span class=\"ansi-cyan-fg\">start_training</span><span class=\"ansi-blue-fg\">(self, trainer)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     94</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     95</span>     <span class=\"ansi-green-fg\">def</span> start_training<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> trainer<span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">&#39;pl.Trainer&#39;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 96</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>training_type_plugin<span class=\"ansi-blue-fg\">.</span>start_training<span class=\"ansi-blue-fg\">(</span>trainer<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     97</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     98</span>     <span class=\"ansi-green-fg\">def</span> start_evaluating<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> trainer<span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">&#39;pl.Trainer&#39;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py</span> in <span class=\"ansi-cyan-fg\">start_training</span><span class=\"ansi-blue-fg\">(self, trainer)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    142</span>     <span class=\"ansi-green-fg\">def</span> start_training<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> trainer<span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">&#39;pl.Trainer&#39;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    143</span>         <span class=\"ansi-red-fg\"># double dispatch to initiate the training loop</span>\n<span class=\"ansi-green-fg\">--&gt; 144</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_results <span class=\"ansi-blue-fg\">=</span> trainer<span class=\"ansi-blue-fg\">.</span>run_stage<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    145</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    146</span>     <span class=\"ansi-green-fg\">def</span> start_evaluating<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> trainer<span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">&#39;pl.Trainer&#39;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py</span> in <span class=\"ansi-cyan-fg\">run_stage</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    805</span>         <span class=\"ansi-green-fg\">if</span> self<span class=\"ansi-blue-fg\">.</span>predicting<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    806</span>             <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>run_predict<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 807</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>run_train<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    808</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    809</span>     <span class=\"ansi-green-fg\">def</span> _pre_training_routine<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py</span> in <span class=\"ansi-cyan-fg\">run_train</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    867</span>                 <span class=\"ansi-green-fg\">with</span> self<span class=\"ansi-blue-fg\">.</span>profiler<span class=\"ansi-blue-fg\">.</span>profile<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;run_training_epoch&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    868</span>                     <span class=\"ansi-red-fg\"># run train epoch</span>\n<span class=\"ansi-green-fg\">--&gt; 869</span><span class=\"ansi-red-fg\">                     </span>self<span class=\"ansi-blue-fg\">.</span>train_loop<span class=\"ansi-blue-fg\">.</span>run_training_epoch<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    870</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    871</span>                 <span class=\"ansi-green-fg\">if</span> self<span class=\"ansi-blue-fg\">.</span>max_steps <span class=\"ansi-green-fg\">and</span> self<span class=\"ansi-blue-fg\">.</span>max_steps <span class=\"ansi-blue-fg\">&lt;=</span> self<span class=\"ansi-blue-fg\">.</span>global_step<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py</span> in <span class=\"ansi-cyan-fg\">run_training_epoch</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    574</span>         <span class=\"ansi-green-fg\">if</span> should_check_val<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    575</span>             self<span class=\"ansi-blue-fg\">.</span>trainer<span class=\"ansi-blue-fg\">.</span>validating <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">True</span>\n<span class=\"ansi-green-fg\">--&gt; 576</span><span class=\"ansi-red-fg\">             </span>self<span class=\"ansi-blue-fg\">.</span>trainer<span class=\"ansi-blue-fg\">.</span>run_evaluation<span class=\"ansi-blue-fg\">(</span>on_epoch<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">True</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    577</span>             self<span class=\"ansi-blue-fg\">.</span>trainer<span class=\"ansi-blue-fg\">.</span>training <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">True</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    578</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py</span> in <span class=\"ansi-cyan-fg\">run_evaluation</span><span class=\"ansi-blue-fg\">(self, on_epoch)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    947</span>             dl_max_batches <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>evaluation_loop<span class=\"ansi-blue-fg\">.</span>max_batches<span class=\"ansi-blue-fg\">[</span>dataloader_idx<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    948</span> \n<span class=\"ansi-green-fg\">--&gt; 949</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">for</span> batch_idx<span class=\"ansi-blue-fg\">,</span> batch <span class=\"ansi-green-fg\">in</span> enumerate<span class=\"ansi-blue-fg\">(</span>dataloader<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    950</span>                 <span class=\"ansi-green-fg\">if</span> batch <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    951</span>                     <span class=\"ansi-green-fg\">continue</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/petastorm/pytorch.py</span> in <span class=\"ansi-cyan-fg\">__iter__</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    114</span>             <span class=\"ansi-green-fg\">raise</span> RuntimeError<span class=\"ansi-blue-fg\">(</span>_PARALLEL_ITER_ERROR<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>         <span class=\"ansi-green-fg\">if</span> self<span class=\"ansi-blue-fg\">.</span>_in_iter <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 116</span><span class=\"ansi-red-fg\">             </span>self<span class=\"ansi-blue-fg\">.</span>reader<span class=\"ansi-blue-fg\">.</span>reset<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    117</span>             logger<span class=\"ansi-blue-fg\">.</span>warning<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;Start a new pass of Petastorm DataLoader, reset underlying Petastorm reader to position 0.&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>         self<span class=\"ansi-blue-fg\">.</span>_in_iter <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">True</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/petastorm/reader.py</span> in <span class=\"ansi-cyan-fg\">reset</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    492</span>             <span class=\"ansi-red-fg\"># drop these in-flight samples? Or just ignore it? What would happen if we have two concurrent ventilators</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    493</span>             <span class=\"ansi-red-fg\"># that are emitting load requests at the same time?</span>\n<span class=\"ansi-green-fg\">--&gt; 494</span><span class=\"ansi-red-fg\">             raise NotImplementedError(&#39;Currently do not support resetting a reader while in the middle of iteration. &#39;\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    495</span>                                       &#39;You can call reset only after all samples were consumed.&#39;)\n<span class=\"ansi-green-intense-fg ansi-bold\">    496</span>         self<span class=\"ansi-blue-fg\">.</span>last_row_consumed <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">False</span>\n\n<span class=\"ansi-red-fg\">NotImplementedError</span>: Currently do not support resetting a reader while in the middle of iteration. You can call reset only after all samples were consumed.</div>","errorSummary":"<span class=\"ansi-red-fg\">NotImplementedError</span>: Currently do not support resetting a reader while in the middle of iteration. You can call reset only after all samples were consumed.","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NotImplementedError</span>                       Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3754394103994545&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     20</span> ) as valid_dataloader:\n<span class=\"ansi-green-intense-fg ansi-bold\">     21</span> \n<span class=\"ansi-green-fg\">---&gt; 22</span><span class=\"ansi-red-fg\">   </span>trainer<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>model<span class=\"ansi-blue-fg\">,</span> train_dataloader<span class=\"ansi-blue-fg\">,</span> valid_dataloader<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     23</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     24</span> run<span class=\"ansi-blue-fg\">.</span>finish<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py</span> in <span class=\"ansi-cyan-fg\">fit</span><span class=\"ansi-blue-fg\">(self, model, train_dataloader, val_dataloaders, datamodule)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    456</span>         )\n<span class=\"ansi-green-intense-fg ansi-bold\">    457</span> \n<span class=\"ansi-green-fg\">--&gt; 458</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_run<span class=\"ansi-blue-fg\">(</span>model<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    459</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    460</span>         <span class=\"ansi-green-fg\">assert</span> self<span class=\"ansi-blue-fg\">.</span>state<span class=\"ansi-blue-fg\">.</span>stopped\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py</span> in <span class=\"ansi-cyan-fg\">_run</span><span class=\"ansi-blue-fg\">(self, model)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    754</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    755</span>         <span class=\"ansi-red-fg\"># dispatch `start_training` or `start_evaluating` or `start_predicting`</span>\n<span class=\"ansi-green-fg\">--&gt; 756</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>dispatch<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    757</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    758</span>         <span class=\"ansi-red-fg\"># plugin will finalized fitting (e.g. ddp_spawn will load trained model)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py</span> in <span class=\"ansi-cyan-fg\">dispatch</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    795</span>             self<span class=\"ansi-blue-fg\">.</span>accelerator<span class=\"ansi-blue-fg\">.</span>start_predicting<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    796</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 797</span><span class=\"ansi-red-fg\">             </span>self<span class=\"ansi-blue-fg\">.</span>accelerator<span class=\"ansi-blue-fg\">.</span>start_training<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    798</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    799</span>     <span class=\"ansi-green-fg\">def</span> run_stage<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py</span> in <span class=\"ansi-cyan-fg\">start_training</span><span class=\"ansi-blue-fg\">(self, trainer)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     94</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     95</span>     <span class=\"ansi-green-fg\">def</span> start_training<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> trainer<span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">&#39;pl.Trainer&#39;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 96</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>training_type_plugin<span class=\"ansi-blue-fg\">.</span>start_training<span class=\"ansi-blue-fg\">(</span>trainer<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     97</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     98</span>     <span class=\"ansi-green-fg\">def</span> start_evaluating<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> trainer<span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">&#39;pl.Trainer&#39;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py</span> in <span class=\"ansi-cyan-fg\">start_training</span><span class=\"ansi-blue-fg\">(self, trainer)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    142</span>     <span class=\"ansi-green-fg\">def</span> start_training<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> trainer<span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">&#39;pl.Trainer&#39;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    143</span>         <span class=\"ansi-red-fg\"># double dispatch to initiate the training loop</span>\n<span class=\"ansi-green-fg\">--&gt; 144</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_results <span class=\"ansi-blue-fg\">=</span> trainer<span class=\"ansi-blue-fg\">.</span>run_stage<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    145</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    146</span>     <span class=\"ansi-green-fg\">def</span> start_evaluating<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> trainer<span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">&#39;pl.Trainer&#39;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py</span> in <span class=\"ansi-cyan-fg\">run_stage</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    805</span>         <span class=\"ansi-green-fg\">if</span> self<span class=\"ansi-blue-fg\">.</span>predicting<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    806</span>             <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>run_predict<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 807</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>run_train<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    808</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    809</span>     <span class=\"ansi-green-fg\">def</span> _pre_training_routine<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py</span> in <span class=\"ansi-cyan-fg\">run_train</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    867</span>                 <span class=\"ansi-green-fg\">with</span> self<span class=\"ansi-blue-fg\">.</span>profiler<span class=\"ansi-blue-fg\">.</span>profile<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;run_training_epoch&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    868</span>                     <span class=\"ansi-red-fg\"># run train epoch</span>\n<span class=\"ansi-green-fg\">--&gt; 869</span><span class=\"ansi-red-fg\">                     </span>self<span class=\"ansi-blue-fg\">.</span>train_loop<span class=\"ansi-blue-fg\">.</span>run_training_epoch<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    870</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    871</span>                 <span class=\"ansi-green-fg\">if</span> self<span class=\"ansi-blue-fg\">.</span>max_steps <span class=\"ansi-green-fg\">and</span> self<span class=\"ansi-blue-fg\">.</span>max_steps <span class=\"ansi-blue-fg\">&lt;=</span> self<span class=\"ansi-blue-fg\">.</span>global_step<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py</span> in <span class=\"ansi-cyan-fg\">run_training_epoch</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    574</span>         <span class=\"ansi-green-fg\">if</span> should_check_val<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    575</span>             self<span class=\"ansi-blue-fg\">.</span>trainer<span class=\"ansi-blue-fg\">.</span>validating <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">True</span>\n<span class=\"ansi-green-fg\">--&gt; 576</span><span class=\"ansi-red-fg\">             </span>self<span class=\"ansi-blue-fg\">.</span>trainer<span class=\"ansi-blue-fg\">.</span>run_evaluation<span class=\"ansi-blue-fg\">(</span>on_epoch<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">True</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    577</span>             self<span class=\"ansi-blue-fg\">.</span>trainer<span class=\"ansi-blue-fg\">.</span>training <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">True</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    578</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py</span> in <span class=\"ansi-cyan-fg\">run_evaluation</span><span class=\"ansi-blue-fg\">(self, on_epoch)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    947</span>             dl_max_batches <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>evaluation_loop<span class=\"ansi-blue-fg\">.</span>max_batches<span class=\"ansi-blue-fg\">[</span>dataloader_idx<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    948</span> \n<span class=\"ansi-green-fg\">--&gt; 949</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">for</span> batch_idx<span class=\"ansi-blue-fg\">,</span> batch <span class=\"ansi-green-fg\">in</span> enumerate<span class=\"ansi-blue-fg\">(</span>dataloader<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    950</span>                 <span class=\"ansi-green-fg\">if</span> batch <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    951</span>                     <span class=\"ansi-green-fg\">continue</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/petastorm/pytorch.py</span> in <span class=\"ansi-cyan-fg\">__iter__</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    114</span>             <span class=\"ansi-green-fg\">raise</span> RuntimeError<span class=\"ansi-blue-fg\">(</span>_PARALLEL_ITER_ERROR<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>         <span class=\"ansi-green-fg\">if</span> self<span class=\"ansi-blue-fg\">.</span>_in_iter <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 116</span><span class=\"ansi-red-fg\">             </span>self<span class=\"ansi-blue-fg\">.</span>reader<span class=\"ansi-blue-fg\">.</span>reset<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    117</span>             logger<span class=\"ansi-blue-fg\">.</span>warning<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;Start a new pass of Petastorm DataLoader, reset underlying Petastorm reader to position 0.&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>         self<span class=\"ansi-blue-fg\">.</span>_in_iter <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">True</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/petastorm/reader.py</span> in <span class=\"ansi-cyan-fg\">reset</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    492</span>             <span class=\"ansi-red-fg\"># drop these in-flight samples? Or just ignore it? What would happen if we have two concurrent ventilators</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    493</span>             <span class=\"ansi-red-fg\"># that are emitting load requests at the same time?</span>\n<span class=\"ansi-green-fg\">--&gt; 494</span><span class=\"ansi-red-fg\">             raise NotImplementedError(&#39;Currently do not support resetting a reader while in the middle of iteration. &#39;\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    495</span>                                       &#39;You can call reset only after all samples were consumed.&#39;)\n<span class=\"ansi-green-intense-fg ansi-bold\">    496</span>         self<span class=\"ansi-blue-fg\">.</span>last_row_consumed <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">False</span>\n\n<span class=\"ansi-red-fg\">NotImplementedError</span>: Currently do not support resetting a reader while in the middle of iteration. You can call reset only after all samples were consumed.</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"dist_forecasting","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2912014336356865}},"nbformat":4,"nbformat_minor":0}
